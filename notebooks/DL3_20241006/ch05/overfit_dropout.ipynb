{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "무작위로 은닉층 노드를 삭제 > 크기를 줄여서 훈련량이 맞추는 너낌~![alt text](image-4.png)\n",
        "![alt text](image-5.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1720147789183
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\EL90\\OneDrive - (주)엘릭서\\MS AI 8기\\수업자료\\workspace\\DL-Excersize\n",
            "c:\\Users\\EL90\\OneDrive - (주)엘릭서\\MS AI 8기\\수업자료\\workspace\n",
            "train loss:2.3127960975323387\n",
            "=== epoch:1, train acc:0.13666666666666666, test acc:0.1017 ===\n",
            "train loss:2.319466175333539\n",
            "train loss:2.309337855985872\n",
            "train loss:2.3066401048742495\n",
            "=== epoch:2, train acc:0.14, test acc:0.1021 ===\n",
            "train loss:2.295564229766378\n",
            "train loss:2.303582799444624\n",
            "train loss:2.3026834930097424\n",
            "=== epoch:3, train acc:0.13666666666666666, test acc:0.1028 ===\n",
            "train loss:2.297782521700952\n",
            "train loss:2.2934707651106208\n",
            "train loss:2.2968595217902976\n",
            "=== epoch:4, train acc:0.13333333333333333, test acc:0.104 ===\n",
            "train loss:2.3029389427429034\n",
            "train loss:2.312223820285816\n",
            "train loss:2.303781433652337\n",
            "=== epoch:5, train acc:0.13333333333333333, test acc:0.1057 ===\n",
            "train loss:2.30878087251011\n",
            "train loss:2.3007107121990886\n",
            "train loss:2.2973229441678567\n",
            "=== epoch:6, train acc:0.14, test acc:0.1055 ===\n",
            "train loss:2.2992971093375885\n",
            "train loss:2.2965582444895114\n",
            "train loss:2.303694553967212\n",
            "=== epoch:7, train acc:0.14333333333333334, test acc:0.1069 ===\n",
            "train loss:2.299908876329447\n",
            "train loss:2.3170816271229158\n",
            "train loss:2.3023483627786434\n",
            "=== epoch:8, train acc:0.14333333333333334, test acc:0.1062 ===\n",
            "train loss:2.2930104167887797\n",
            "train loss:2.290111161776125\n",
            "train loss:2.2951742434281512\n",
            "=== epoch:9, train acc:0.14, test acc:0.1066 ===\n",
            "train loss:2.30253202705348\n",
            "train loss:2.28952660124352\n",
            "train loss:2.301509383385239\n",
            "=== epoch:10, train acc:0.13666666666666666, test acc:0.1065 ===\n",
            "train loss:2.2973755197260153\n",
            "train loss:2.300072774929344\n",
            "train loss:2.30051568092386\n",
            "=== epoch:11, train acc:0.14333333333333334, test acc:0.1084 ===\n",
            "train loss:2.2912746454690964\n",
            "train loss:2.303265168558129\n",
            "train loss:2.3000812443136054\n",
            "=== epoch:12, train acc:0.14, test acc:0.1092 ===\n",
            "train loss:2.3008424804997416\n",
            "train loss:2.3020758857469814\n",
            "train loss:2.2979655592107555\n",
            "=== epoch:13, train acc:0.13666666666666666, test acc:0.111 ===\n",
            "train loss:2.3056430703331627\n",
            "train loss:2.291649461920366\n",
            "train loss:2.2937687465068373\n",
            "=== epoch:14, train acc:0.14333333333333334, test acc:0.1113 ===\n",
            "train loss:2.3005281640725226\n",
            "train loss:2.3047458727516696\n",
            "train loss:2.296654788090565\n",
            "=== epoch:15, train acc:0.13666666666666666, test acc:0.1134 ===\n",
            "train loss:2.296789569406402\n",
            "train loss:2.2968603886366545\n",
            "train loss:2.30054549049806\n",
            "=== epoch:16, train acc:0.14333333333333334, test acc:0.1137 ===\n",
            "train loss:2.2980416113132276\n",
            "train loss:2.2964368113190297\n",
            "train loss:2.2945804984444877\n",
            "=== epoch:17, train acc:0.13333333333333333, test acc:0.113 ===\n",
            "train loss:2.2925867146724466\n",
            "train loss:2.2982628604042112\n",
            "train loss:2.292388497479769\n",
            "=== epoch:18, train acc:0.13666666666666666, test acc:0.112 ===\n",
            "train loss:2.290676981582\n",
            "train loss:2.299465439742367\n",
            "train loss:2.3014824584141476\n",
            "=== epoch:19, train acc:0.13, test acc:0.1108 ===\n",
            "train loss:2.291129113064811\n",
            "train loss:2.2964054420726008\n",
            "train loss:2.3009776757154965\n",
            "=== epoch:20, train acc:0.13333333333333333, test acc:0.1131 ===\n",
            "train loss:2.3029331723110387\n",
            "train loss:2.297238045600464\n",
            "train loss:2.3048574264277644\n",
            "=== epoch:21, train acc:0.13666666666666666, test acc:0.1128 ===\n",
            "train loss:2.28827295054417\n",
            "train loss:2.295497528396579\n",
            "train loss:2.296672313505592\n",
            "=== epoch:22, train acc:0.14333333333333334, test acc:0.1129 ===\n",
            "train loss:2.293724170587036\n",
            "train loss:2.2957268239782955\n",
            "train loss:2.2943155626005645\n",
            "=== epoch:23, train acc:0.13666666666666666, test acc:0.1141 ===\n",
            "train loss:2.295388657248464\n",
            "train loss:2.3007677832757962\n",
            "train loss:2.2966945067459346\n",
            "=== epoch:24, train acc:0.14666666666666667, test acc:0.116 ===\n",
            "train loss:2.283131671073395\n",
            "train loss:2.290794075383501\n",
            "train loss:2.2903322748697423\n",
            "=== epoch:25, train acc:0.14333333333333334, test acc:0.1166 ===\n",
            "train loss:2.301899347123127\n",
            "train loss:2.2875692993906984\n",
            "train loss:2.292456883876729\n",
            "=== epoch:26, train acc:0.15, test acc:0.1179 ===\n",
            "train loss:2.2830899616919766\n",
            "train loss:2.2978870115751766\n",
            "train loss:2.2934768762763054\n",
            "=== epoch:27, train acc:0.15, test acc:0.1176 ===\n",
            "train loss:2.2963006245798865\n",
            "train loss:2.2873799657741336\n",
            "train loss:2.2956247514644867\n",
            "=== epoch:28, train acc:0.14666666666666667, test acc:0.1183 ===\n",
            "train loss:2.2963188998627997\n",
            "train loss:2.294563357916956\n",
            "train loss:2.2808398028949055\n",
            "=== epoch:29, train acc:0.15, test acc:0.1176 ===\n",
            "train loss:2.2882694090803914\n",
            "train loss:2.2905084655173535\n",
            "train loss:2.2936029857275826\n",
            "=== epoch:30, train acc:0.14333333333333334, test acc:0.1178 ===\n",
            "train loss:2.2849625715731636\n",
            "train loss:2.290734154942252\n",
            "train loss:2.2853925253094896\n",
            "=== epoch:31, train acc:0.14, test acc:0.119 ===\n",
            "train loss:2.2916265128005424\n",
            "train loss:2.2876640505393997\n",
            "train loss:2.290635866592642\n",
            "=== epoch:32, train acc:0.14, test acc:0.1184 ===\n",
            "train loss:2.295895025497334\n",
            "train loss:2.301396650443452\n",
            "train loss:2.292538045675985\n",
            "=== epoch:33, train acc:0.14, test acc:0.1196 ===\n",
            "train loss:2.292538010905485\n",
            "train loss:2.294983480456343\n",
            "train loss:2.2972396291993555\n",
            "=== epoch:34, train acc:0.14, test acc:0.1206 ===\n",
            "train loss:2.2886738491229095\n",
            "train loss:2.291501279783516\n",
            "train loss:2.2904191131721863\n",
            "=== epoch:35, train acc:0.14, test acc:0.1211 ===\n",
            "train loss:2.2919433169995864\n",
            "train loss:2.2855324833516963\n",
            "train loss:2.2928395701604116\n",
            "=== epoch:36, train acc:0.15, test acc:0.123 ===\n",
            "train loss:2.2839929914813575\n",
            "train loss:2.2897315138341736\n",
            "train loss:2.2914277739116593\n",
            "=== epoch:37, train acc:0.15666666666666668, test acc:0.1265 ===\n",
            "train loss:2.294917800039099\n",
            "train loss:2.2929752965916403\n",
            "train loss:2.2842440646221394\n",
            "=== epoch:38, train acc:0.16333333333333333, test acc:0.1281 ===\n",
            "train loss:2.2911584064034205\n",
            "train loss:2.286653648166643\n",
            "train loss:2.2873920374833983\n",
            "=== epoch:39, train acc:0.16, test acc:0.1295 ===\n",
            "train loss:2.2943027892397385\n",
            "train loss:2.285979756693442\n",
            "train loss:2.284420887805352\n",
            "=== epoch:40, train acc:0.15666666666666668, test acc:0.1301 ===\n",
            "train loss:2.2944966875560375\n",
            "train loss:2.2890441406981794\n",
            "train loss:2.285324243940538\n",
            "=== epoch:41, train acc:0.16, test acc:0.1317 ===\n",
            "train loss:2.2853012192226445\n",
            "train loss:2.287562665250905\n",
            "train loss:2.2864721973701245\n",
            "=== epoch:42, train acc:0.15666666666666668, test acc:0.1348 ===\n",
            "train loss:2.2891130187644624\n",
            "train loss:2.2875690627454137\n",
            "train loss:2.283405787077956\n",
            "=== epoch:43, train acc:0.16, test acc:0.1372 ===\n",
            "train loss:2.2929411639064434\n",
            "train loss:2.290163571763008\n",
            "train loss:2.290603068800163\n",
            "=== epoch:44, train acc:0.16, test acc:0.1386 ===\n",
            "train loss:2.28608286484742\n",
            "train loss:2.294975541548613\n",
            "train loss:2.286721704677866\n",
            "=== epoch:45, train acc:0.15666666666666668, test acc:0.1395 ===\n",
            "train loss:2.2873038973123605\n",
            "train loss:2.2837358923755118\n",
            "train loss:2.2997700762848567\n",
            "=== epoch:46, train acc:0.16666666666666666, test acc:0.1415 ===\n",
            "train loss:2.284669479366076\n",
            "train loss:2.28390015307717\n",
            "train loss:2.287723923669786\n",
            "=== epoch:47, train acc:0.16666666666666666, test acc:0.1421 ===\n",
            "train loss:2.286720852626611\n",
            "train loss:2.2790472583394346\n",
            "train loss:2.291891305079961\n",
            "=== epoch:48, train acc:0.17666666666666667, test acc:0.1475 ===\n",
            "train loss:2.285288991321355\n",
            "train loss:2.28625386929244\n",
            "train loss:2.290986847360183\n",
            "=== epoch:49, train acc:0.18666666666666668, test acc:0.1522 ===\n",
            "train loss:2.2813067713898345\n",
            "train loss:2.294532493904236\n",
            "train loss:2.2821104006442168\n",
            "=== epoch:50, train acc:0.19666666666666666, test acc:0.1531 ===\n",
            "train loss:2.2883889114876985\n",
            "train loss:2.2854742324380433\n",
            "train loss:2.294346522973601\n",
            "=== epoch:51, train acc:0.2, test acc:0.1571 ===\n",
            "train loss:2.286850813145556\n",
            "train loss:2.286000772379671\n",
            "train loss:2.295032879765343\n",
            "=== epoch:52, train acc:0.20666666666666667, test acc:0.1593 ===\n",
            "train loss:2.287869212389852\n",
            "train loss:2.2819797840760674\n",
            "train loss:2.283400334750955\n",
            "=== epoch:53, train acc:0.2, test acc:0.1601 ===\n",
            "train loss:2.281694221053876\n",
            "train loss:2.295575509856357\n",
            "train loss:2.286163117363012\n",
            "=== epoch:54, train acc:0.21, test acc:0.1636 ===\n",
            "train loss:2.2884854861949555\n",
            "train loss:2.2881819702632935\n",
            "train loss:2.277276035690866\n",
            "=== epoch:55, train acc:0.2, test acc:0.162 ===\n",
            "train loss:2.2857710024161024\n",
            "train loss:2.2760824339068852\n",
            "train loss:2.288249979393639\n",
            "=== epoch:56, train acc:0.21666666666666667, test acc:0.1666 ===\n",
            "train loss:2.288125267951944\n",
            "train loss:2.2823443854076295\n",
            "train loss:2.2795421089577146\n",
            "=== epoch:57, train acc:0.20333333333333334, test acc:0.1652 ===\n",
            "train loss:2.287575225495082\n",
            "train loss:2.28662509656053\n",
            "train loss:2.2824253568833885\n",
            "=== epoch:58, train acc:0.19666666666666666, test acc:0.171 ===\n",
            "train loss:2.2800623553139157\n",
            "train loss:2.2867942468107745\n",
            "train loss:2.2845816904604748\n",
            "=== epoch:59, train acc:0.21, test acc:0.1745 ===\n",
            "train loss:2.2787701177279107\n",
            "train loss:2.276911295800305\n",
            "train loss:2.2782375021176673\n",
            "=== epoch:60, train acc:0.21333333333333335, test acc:0.1744 ===\n",
            "train loss:2.2811703472674383\n",
            "train loss:2.2908292251391877\n",
            "train loss:2.2793787847142766\n",
            "=== epoch:61, train acc:0.21333333333333335, test acc:0.1763 ===\n",
            "train loss:2.288972033389182\n",
            "train loss:2.283833107057284\n",
            "train loss:2.2804895459873133\n",
            "=== epoch:62, train acc:0.21, test acc:0.1798 ===\n",
            "train loss:2.2822163751813496\n",
            "train loss:2.2799557251326643\n",
            "train loss:2.2739919278052714\n",
            "=== epoch:63, train acc:0.23, test acc:0.1856 ===\n",
            "train loss:2.274779329364608\n",
            "train loss:2.2867248155843223\n",
            "train loss:2.280578293233709\n",
            "=== epoch:64, train acc:0.23333333333333334, test acc:0.1834 ===\n",
            "train loss:2.279882001425064\n",
            "train loss:2.277159052006586\n",
            "train loss:2.2800234307573315\n",
            "=== epoch:65, train acc:0.23333333333333334, test acc:0.186 ===\n",
            "train loss:2.2927421141783886\n",
            "train loss:2.268102444552338\n",
            "train loss:2.274403723745784\n",
            "=== epoch:66, train acc:0.23, test acc:0.1879 ===\n",
            "train loss:2.2832869711442227\n",
            "train loss:2.2768142348303977\n",
            "train loss:2.271408492976106\n",
            "=== epoch:67, train acc:0.23, test acc:0.1858 ===\n",
            "train loss:2.2852915441388704\n",
            "train loss:2.2733427986669805\n",
            "train loss:2.269244566471582\n",
            "=== epoch:68, train acc:0.22666666666666666, test acc:0.1897 ===\n",
            "train loss:2.284867628097253\n",
            "train loss:2.286847786957901\n",
            "train loss:2.2787596257783598\n",
            "=== epoch:69, train acc:0.22666666666666666, test acc:0.1874 ===\n",
            "train loss:2.2760566427027027\n",
            "train loss:2.2791161402066558\n",
            "train loss:2.2928300972898468\n",
            "=== epoch:70, train acc:0.23, test acc:0.1907 ===\n",
            "train loss:2.2814661500932285\n",
            "train loss:2.2869885823942493\n",
            "train loss:2.2861867810662644\n",
            "=== epoch:71, train acc:0.23, test acc:0.1925 ===\n",
            "train loss:2.277730985585869\n",
            "train loss:2.2809084717772525\n",
            "train loss:2.2812431371539215\n",
            "=== epoch:72, train acc:0.23333333333333334, test acc:0.1955 ===\n",
            "train loss:2.278740475874263\n",
            "train loss:2.2763978806406224\n",
            "train loss:2.2761540772644224\n",
            "=== epoch:73, train acc:0.24666666666666667, test acc:0.1984 ===\n",
            "train loss:2.2733903380190092\n",
            "train loss:2.2678789963888697\n",
            "train loss:2.292405244419155\n",
            "=== epoch:74, train acc:0.24666666666666667, test acc:0.1987 ===\n",
            "train loss:2.2743452901211536\n",
            "train loss:2.2753380308593196\n",
            "train loss:2.2812077635701145\n",
            "=== epoch:75, train acc:0.24666666666666667, test acc:0.2007 ===\n",
            "train loss:2.2704211882472034\n",
            "train loss:2.2836149108551704\n",
            "train loss:2.267418568773675\n",
            "=== epoch:76, train acc:0.25, test acc:0.2028 ===\n",
            "train loss:2.273579521696053\n",
            "train loss:2.2739525770530538\n",
            "train loss:2.2893611739831004\n",
            "=== epoch:77, train acc:0.25333333333333335, test acc:0.204 ===\n",
            "train loss:2.2802118828837714\n",
            "train loss:2.2811728657029637\n",
            "train loss:2.2679279684017692\n",
            "=== epoch:78, train acc:0.26666666666666666, test acc:0.207 ===\n",
            "train loss:2.2777759857893987\n",
            "train loss:2.2863457163974306\n",
            "train loss:2.2718761664930995\n",
            "=== epoch:79, train acc:0.2633333333333333, test acc:0.2077 ===\n",
            "train loss:2.273730480446515\n",
            "train loss:2.2790430155039787\n",
            "train loss:2.265582981633605\n",
            "=== epoch:80, train acc:0.24666666666666667, test acc:0.2065 ===\n",
            "train loss:2.267915541659466\n",
            "train loss:2.2895322936604967\n",
            "train loss:2.2696490276761563\n",
            "=== epoch:81, train acc:0.25666666666666665, test acc:0.2085 ===\n",
            "train loss:2.278552667562146\n",
            "train loss:2.2763405964015515\n",
            "train loss:2.265848586146199\n",
            "=== epoch:82, train acc:0.25666666666666665, test acc:0.2095 ===\n",
            "train loss:2.279929381746772\n",
            "train loss:2.2842842404425845\n",
            "train loss:2.2927609267154465\n",
            "=== epoch:83, train acc:0.2633333333333333, test acc:0.2108 ===\n",
            "train loss:2.284582245472909\n",
            "train loss:2.2785488517639605\n",
            "train loss:2.2860841022460865\n",
            "=== epoch:84, train acc:0.25333333333333335, test acc:0.2116 ===\n",
            "train loss:2.276681839834221\n",
            "train loss:2.2722500834448587\n",
            "train loss:2.266404477599728\n",
            "=== epoch:85, train acc:0.25666666666666665, test acc:0.2113 ===\n",
            "train loss:2.2749890955763843\n",
            "train loss:2.3011098430054266\n",
            "train loss:2.2710589850940712\n",
            "=== epoch:86, train acc:0.24, test acc:0.211 ===\n",
            "train loss:2.2745341005283475\n",
            "train loss:2.280500757608119\n",
            "train loss:2.2841262797461552\n",
            "=== epoch:87, train acc:0.23333333333333334, test acc:0.2124 ===\n",
            "train loss:2.2764898296720197\n",
            "train loss:2.2710015679006093\n",
            "train loss:2.28406293189217\n",
            "=== epoch:88, train acc:0.23666666666666666, test acc:0.213 ===\n",
            "train loss:2.277412219477412\n",
            "train loss:2.27596618785588\n",
            "train loss:2.272028375352112\n",
            "=== epoch:89, train acc:0.23666666666666666, test acc:0.2134 ===\n",
            "train loss:2.27636333198535\n",
            "train loss:2.2757545034003233\n",
            "train loss:2.2663983624309254\n",
            "=== epoch:90, train acc:0.24333333333333335, test acc:0.2122 ===\n",
            "train loss:2.273060099497509\n",
            "train loss:2.2813072602760704\n",
            "train loss:2.275675612203267\n",
            "=== epoch:91, train acc:0.24666666666666667, test acc:0.2142 ===\n",
            "train loss:2.268262370679508\n",
            "train loss:2.2770704215098094\n",
            "train loss:2.2639955498808924\n",
            "=== epoch:92, train acc:0.25, test acc:0.2162 ===\n",
            "train loss:2.2711684406671533\n",
            "train loss:2.2749490732649593\n",
            "train loss:2.28307288503686\n",
            "=== epoch:93, train acc:0.24333333333333335, test acc:0.2136 ===\n",
            "train loss:2.289188970489251\n",
            "train loss:2.266410870554642\n",
            "train loss:2.2757252296655746\n",
            "=== epoch:94, train acc:0.25, test acc:0.2139 ===\n",
            "train loss:2.2792456194258275\n",
            "train loss:2.268922552130948\n",
            "train loss:2.2680322071565793\n",
            "=== epoch:95, train acc:0.25, test acc:0.2136 ===\n",
            "train loss:2.2713725353180068\n",
            "train loss:2.2842640382849613\n",
            "train loss:2.262240765521614\n",
            "=== epoch:96, train acc:0.24666666666666667, test acc:0.2153 ===\n",
            "train loss:2.2711183616505535\n",
            "train loss:2.2848168994581837\n",
            "train loss:2.279477662502035\n",
            "=== epoch:97, train acc:0.24666666666666667, test acc:0.2144 ===\n",
            "train loss:2.2697092702259516\n",
            "train loss:2.278215749899474\n",
            "train loss:2.2781247865213494\n",
            "=== epoch:98, train acc:0.24333333333333335, test acc:0.214 ===\n",
            "train loss:2.2717683306707097\n",
            "train loss:2.268256313030813\n",
            "train loss:2.272862871442278\n",
            "=== epoch:99, train acc:0.24333333333333335, test acc:0.2145 ===\n",
            "train loss:2.2677826156522722\n",
            "train loss:2.27101330442296\n",
            "train loss:2.2666559688228545\n",
            "=== epoch:100, train acc:0.24, test acc:0.2134 ===\n",
            "train loss:2.2735206788034974\n",
            "train loss:2.2766767162049275\n",
            "train loss:2.2690971791126824\n",
            "=== epoch:101, train acc:0.24333333333333335, test acc:0.2143 ===\n",
            "train loss:2.264138465075065\n",
            "train loss:2.272139921986299\n",
            "train loss:2.2721615266097026\n",
            "=== epoch:102, train acc:0.24, test acc:0.2137 ===\n",
            "train loss:2.2722024552759597\n",
            "train loss:2.255757610535114\n",
            "train loss:2.2747252447685375\n",
            "=== epoch:103, train acc:0.24666666666666667, test acc:0.2148 ===\n",
            "train loss:2.2720153865714625\n",
            "train loss:2.2833728833808813\n",
            "train loss:2.283416186661741\n",
            "=== epoch:104, train acc:0.24, test acc:0.214 ===\n",
            "train loss:2.2813968514712513\n",
            "train loss:2.2704670893799035\n",
            "train loss:2.2788508052666443\n",
            "=== epoch:105, train acc:0.24666666666666667, test acc:0.2147 ===\n",
            "train loss:2.2696117752135283\n",
            "train loss:2.2647264620348473\n",
            "train loss:2.2648831257745905\n",
            "=== epoch:106, train acc:0.24666666666666667, test acc:0.2145 ===\n",
            "train loss:2.2703980384857623\n",
            "train loss:2.2733241561409794\n",
            "train loss:2.2538050645936414\n",
            "=== epoch:107, train acc:0.24333333333333335, test acc:0.2154 ===\n",
            "train loss:2.2642628998279735\n",
            "train loss:2.271016127481666\n",
            "train loss:2.270685052364441\n",
            "=== epoch:108, train acc:0.25333333333333335, test acc:0.2166 ===\n",
            "train loss:2.26101056556477\n",
            "train loss:2.2657989068732003\n",
            "train loss:2.27868214538361\n",
            "=== epoch:109, train acc:0.24333333333333335, test acc:0.2155 ===\n",
            "train loss:2.2630496323230345\n",
            "train loss:2.2615046728603416\n",
            "train loss:2.271667625856134\n",
            "=== epoch:110, train acc:0.24666666666666667, test acc:0.2183 ===\n",
            "train loss:2.2719847394513946\n",
            "train loss:2.2699133613100715\n",
            "train loss:2.275418153824136\n",
            "=== epoch:111, train acc:0.25, test acc:0.2182 ===\n",
            "train loss:2.2647675921156467\n",
            "train loss:2.253624789793597\n",
            "train loss:2.2595834924611213\n",
            "=== epoch:112, train acc:0.25, test acc:0.2189 ===\n",
            "train loss:2.2692623420880014\n",
            "train loss:2.2649057958338954\n",
            "train loss:2.2661669435149614\n",
            "=== epoch:113, train acc:0.25, test acc:0.2172 ===\n",
            "train loss:2.259438581841982\n",
            "train loss:2.2601853376057246\n",
            "train loss:2.2865327498187638\n",
            "=== epoch:114, train acc:0.25, test acc:0.2173 ===\n",
            "train loss:2.2556255868897344\n",
            "train loss:2.2697486214293208\n",
            "train loss:2.2601188481522767\n",
            "=== epoch:115, train acc:0.25333333333333335, test acc:0.2178 ===\n",
            "train loss:2.260991116541503\n",
            "train loss:2.262972886398187\n",
            "train loss:2.2745612950729415\n",
            "=== epoch:116, train acc:0.25, test acc:0.2164 ===\n",
            "train loss:2.257867001756173\n",
            "train loss:2.2691051506538202\n",
            "train loss:2.281133399864732\n",
            "=== epoch:117, train acc:0.26, test acc:0.2185 ===\n",
            "train loss:2.263865398105663\n",
            "train loss:2.27149646254723\n",
            "train loss:2.255762843716695\n",
            "=== epoch:118, train acc:0.26, test acc:0.2217 ===\n",
            "train loss:2.253082836745557\n",
            "train loss:2.2796318147655135\n",
            "train loss:2.250061141092549\n",
            "=== epoch:119, train acc:0.25666666666666665, test acc:0.2192 ===\n",
            "train loss:2.2886341848047365\n",
            "train loss:2.2641280990948682\n",
            "train loss:2.268486903260006\n",
            "=== epoch:120, train acc:0.26, test acc:0.2211 ===\n",
            "train loss:2.2640509176370807\n",
            "train loss:2.255060435016378\n",
            "train loss:2.27684704837638\n",
            "=== epoch:121, train acc:0.26, test acc:0.2227 ===\n",
            "train loss:2.2786984977537568\n",
            "train loss:2.2564784618757994\n",
            "train loss:2.2753709587042685\n",
            "=== epoch:122, train acc:0.26666666666666666, test acc:0.2209 ===\n",
            "train loss:2.269900104447087\n",
            "train loss:2.2681991187132295\n",
            "train loss:2.263423621772763\n",
            "=== epoch:123, train acc:0.2733333333333333, test acc:0.2237 ===\n",
            "train loss:2.2605705688447624\n",
            "train loss:2.2598435647903865\n",
            "train loss:2.2674040093444416\n",
            "=== epoch:124, train acc:0.27, test acc:0.2224 ===\n",
            "train loss:2.2604313527776636\n",
            "train loss:2.2477471535972184\n",
            "train loss:2.261971420001207\n",
            "=== epoch:125, train acc:0.27666666666666667, test acc:0.2238 ===\n",
            "train loss:2.271235507273919\n",
            "train loss:2.2585353972183895\n",
            "train loss:2.2730759174125197\n",
            "=== epoch:126, train acc:0.2633333333333333, test acc:0.2221 ===\n",
            "train loss:2.238443193591313\n",
            "train loss:2.2828848501594923\n",
            "train loss:2.26971275698211\n",
            "=== epoch:127, train acc:0.26666666666666666, test acc:0.2216 ===\n",
            "train loss:2.2616144985257893\n",
            "train loss:2.2664907426143306\n",
            "train loss:2.271982165045901\n",
            "=== epoch:128, train acc:0.27, test acc:0.2228 ===\n",
            "train loss:2.263116412217978\n",
            "train loss:2.2772094407647865\n",
            "train loss:2.264323933087283\n",
            "=== epoch:129, train acc:0.26666666666666666, test acc:0.2241 ===\n",
            "train loss:2.262629154820608\n",
            "train loss:2.265665559611553\n",
            "train loss:2.2618802548172767\n",
            "=== epoch:130, train acc:0.26666666666666666, test acc:0.2242 ===\n",
            "train loss:2.2596076270966807\n",
            "train loss:2.2664323370222523\n",
            "train loss:2.2530114724659827\n",
            "=== epoch:131, train acc:0.26666666666666666, test acc:0.2235 ===\n",
            "train loss:2.261323476090173\n",
            "train loss:2.2528857484570826\n",
            "train loss:2.258560252170488\n",
            "=== epoch:132, train acc:0.26666666666666666, test acc:0.2217 ===\n",
            "train loss:2.2468993975229496\n",
            "train loss:2.2535053577988933\n",
            "train loss:2.2469413577871573\n",
            "=== epoch:133, train acc:0.27, test acc:0.223 ===\n",
            "train loss:2.2637378147243377\n",
            "train loss:2.2660444756367846\n",
            "train loss:2.2720893161142617\n",
            "=== epoch:134, train acc:0.26666666666666666, test acc:0.2226 ===\n",
            "train loss:2.2600726847319565\n",
            "train loss:2.264180407817851\n",
            "train loss:2.258814248210401\n",
            "=== epoch:135, train acc:0.27, test acc:0.2242 ===\n",
            "train loss:2.2752525997552584\n",
            "train loss:2.268665889937414\n",
            "train loss:2.278816077116314\n",
            "=== epoch:136, train acc:0.26, test acc:0.2226 ===\n",
            "train loss:2.2631223342196325\n",
            "train loss:2.254192904694835\n",
            "train loss:2.2591786134659824\n",
            "=== epoch:137, train acc:0.27, test acc:0.2234 ===\n",
            "train loss:2.268191252036224\n",
            "train loss:2.2816494583524904\n",
            "train loss:2.2445100660713044\n",
            "=== epoch:138, train acc:0.27666666666666667, test acc:0.2275 ===\n",
            "train loss:2.2738445151196753\n",
            "train loss:2.24276289471935\n",
            "train loss:2.266966501073715\n",
            "=== epoch:139, train acc:0.28, test acc:0.2286 ===\n",
            "train loss:2.2623785340876323\n",
            "train loss:2.2558948361089093\n",
            "train loss:2.250950529363466\n",
            "=== epoch:140, train acc:0.28, test acc:0.2273 ===\n",
            "train loss:2.251493927704692\n",
            "train loss:2.252136197048172\n",
            "train loss:2.2750268741262216\n",
            "=== epoch:141, train acc:0.2866666666666667, test acc:0.2313 ===\n",
            "train loss:2.274791700114512\n",
            "train loss:2.2576571078983334\n",
            "train loss:2.240430480457391\n",
            "=== epoch:142, train acc:0.28, test acc:0.2304 ===\n",
            "train loss:2.244348671302654\n",
            "train loss:2.265556829090254\n",
            "train loss:2.245602192300349\n",
            "=== epoch:143, train acc:0.2733333333333333, test acc:0.2295 ===\n",
            "train loss:2.2601374437972086\n",
            "train loss:2.263681790249157\n",
            "train loss:2.2721476257953634\n",
            "=== epoch:144, train acc:0.28, test acc:0.2305 ===\n",
            "train loss:2.265731068100001\n",
            "train loss:2.253149251635983\n",
            "train loss:2.2699102325525637\n",
            "=== epoch:145, train acc:0.2866666666666667, test acc:0.2325 ===\n",
            "train loss:2.270373101516903\n",
            "train loss:2.2694693849493377\n",
            "train loss:2.257621812463255\n",
            "=== epoch:146, train acc:0.2833333333333333, test acc:0.2335 ===\n",
            "train loss:2.256828970288548\n",
            "train loss:2.251165210426551\n",
            "train loss:2.2737830618715362\n",
            "=== epoch:147, train acc:0.2833333333333333, test acc:0.2332 ===\n",
            "train loss:2.2564764620083007\n",
            "train loss:2.246844312590568\n",
            "train loss:2.2491381448577474\n",
            "=== epoch:148, train acc:0.28, test acc:0.2325 ===\n",
            "train loss:2.244505415788986\n",
            "train loss:2.2467177934251628\n",
            "train loss:2.247072018304881\n",
            "=== epoch:149, train acc:0.29, test acc:0.2341 ===\n",
            "train loss:2.238290448487104\n",
            "train loss:2.2518767966608295\n",
            "train loss:2.2505518065109533\n",
            "=== epoch:150, train acc:0.2866666666666667, test acc:0.2341 ===\n",
            "train loss:2.2530272413872927\n",
            "train loss:2.273446915773533\n",
            "train loss:2.2469509558826237\n",
            "=== epoch:151, train acc:0.2833333333333333, test acc:0.2341 ===\n",
            "train loss:2.2524352156101246\n",
            "train loss:2.2588127112886656\n",
            "train loss:2.2502172157909412\n",
            "=== epoch:152, train acc:0.2833333333333333, test acc:0.2337 ===\n",
            "train loss:2.2783842094092144\n",
            "train loss:2.2523963398990583\n",
            "train loss:2.2372416682195073\n",
            "=== epoch:153, train acc:0.28, test acc:0.2331 ===\n",
            "train loss:2.2583056773177614\n",
            "train loss:2.246633274093248\n",
            "train loss:2.2578095606802533\n",
            "=== epoch:154, train acc:0.2733333333333333, test acc:0.2325 ===\n",
            "train loss:2.264286743658709\n",
            "train loss:2.242884020814324\n",
            "train loss:2.2546509494370133\n",
            "=== epoch:155, train acc:0.28, test acc:0.2331 ===\n",
            "train loss:2.269656204813686\n",
            "train loss:2.2454762658341134\n",
            "train loss:2.2482835163315347\n",
            "=== epoch:156, train acc:0.2733333333333333, test acc:0.2303 ===\n",
            "train loss:2.2649280143335995\n",
            "train loss:2.2632664423337965\n",
            "train loss:2.255555786852673\n",
            "=== epoch:157, train acc:0.2733333333333333, test acc:0.2307 ===\n",
            "train loss:2.270836343160564\n",
            "train loss:2.258325402030253\n",
            "train loss:2.249532383901966\n",
            "=== epoch:158, train acc:0.27666666666666667, test acc:0.2325 ===\n",
            "train loss:2.239951699294827\n",
            "train loss:2.260401788318465\n",
            "train loss:2.256842344990955\n",
            "=== epoch:159, train acc:0.2733333333333333, test acc:0.231 ===\n",
            "train loss:2.27832934019048\n",
            "train loss:2.231773538904299\n",
            "train loss:2.252107818834196\n",
            "=== epoch:160, train acc:0.2733333333333333, test acc:0.2296 ===\n",
            "train loss:2.271820830304432\n",
            "train loss:2.2502809890362854\n",
            "train loss:2.25618098741712\n",
            "=== epoch:161, train acc:0.27666666666666667, test acc:0.2318 ===\n",
            "train loss:2.2803405643729153\n",
            "train loss:2.2700114356473886\n",
            "train loss:2.2476845888358135\n",
            "=== epoch:162, train acc:0.27666666666666667, test acc:0.2308 ===\n",
            "train loss:2.255614506102792\n",
            "train loss:2.2418374289695215\n",
            "train loss:2.2355805714455577\n",
            "=== epoch:163, train acc:0.2733333333333333, test acc:0.2299 ===\n",
            "train loss:2.2511723724072885\n",
            "train loss:2.2499506665825915\n",
            "train loss:2.2357500961960075\n",
            "=== epoch:164, train acc:0.2733333333333333, test acc:0.2285 ===\n",
            "train loss:2.239706076335718\n",
            "train loss:2.2574060069945983\n",
            "train loss:2.2645260717881537\n",
            "=== epoch:165, train acc:0.2733333333333333, test acc:0.2307 ===\n",
            "train loss:2.2638549089993236\n",
            "train loss:2.2545559297709534\n",
            "train loss:2.2637282194932338\n",
            "=== epoch:166, train acc:0.2733333333333333, test acc:0.2323 ===\n",
            "train loss:2.22835330644873\n",
            "train loss:2.2435309378157573\n",
            "train loss:2.246496587228309\n",
            "=== epoch:167, train acc:0.2733333333333333, test acc:0.2326 ===\n",
            "train loss:2.268814881863059\n",
            "train loss:2.2467000564878727\n",
            "train loss:2.2425147791943534\n",
            "=== epoch:168, train acc:0.27666666666666667, test acc:0.2316 ===\n",
            "train loss:2.2379185338868384\n",
            "train loss:2.251252917281813\n",
            "train loss:2.2415333215307562\n",
            "=== epoch:169, train acc:0.28, test acc:0.2345 ===\n",
            "train loss:2.2600552173143593\n",
            "train loss:2.2640387036800496\n",
            "train loss:2.259512416074132\n",
            "=== epoch:170, train acc:0.27666666666666667, test acc:0.2364 ===\n",
            "train loss:2.2362762365454643\n",
            "train loss:2.2521814369577524\n",
            "train loss:2.2438138418210043\n",
            "=== epoch:171, train acc:0.28, test acc:0.2376 ===\n",
            "train loss:2.248179542817313\n",
            "train loss:2.2450983228469776\n",
            "train loss:2.2236452017979342\n",
            "=== epoch:172, train acc:0.28, test acc:0.2374 ===\n",
            "train loss:2.2503206035996257\n",
            "train loss:2.2272982425768477\n",
            "train loss:2.265155421595757\n",
            "=== epoch:173, train acc:0.2833333333333333, test acc:0.2363 ===\n",
            "train loss:2.251133011881631\n",
            "train loss:2.251857133395901\n",
            "train loss:2.257798978409222\n",
            "=== epoch:174, train acc:0.2833333333333333, test acc:0.2375 ===\n",
            "train loss:2.2403485582329097\n",
            "train loss:2.2649336835265714\n",
            "train loss:2.238379755862908\n",
            "=== epoch:175, train acc:0.2866666666666667, test acc:0.2385 ===\n",
            "train loss:2.2453670496858296\n",
            "train loss:2.255938062116016\n",
            "train loss:2.2432345395698277\n",
            "=== epoch:176, train acc:0.2866666666666667, test acc:0.2385 ===\n",
            "train loss:2.2588496712877264\n",
            "train loss:2.2485018614160706\n",
            "train loss:2.2420532227819443\n",
            "=== epoch:177, train acc:0.29333333333333333, test acc:0.2404 ===\n",
            "train loss:2.227451960548492\n",
            "train loss:2.2567977418587635\n",
            "train loss:2.2428051186796747\n",
            "=== epoch:178, train acc:0.2866666666666667, test acc:0.2393 ===\n",
            "train loss:2.2436568723268735\n",
            "train loss:2.255139576288056\n",
            "train loss:2.251136473781172\n",
            "=== epoch:179, train acc:0.28, test acc:0.2389 ===\n",
            "train loss:2.241633112834203\n",
            "train loss:2.250566376588327\n",
            "train loss:2.253072060569089\n",
            "=== epoch:180, train acc:0.28, test acc:0.2385 ===\n",
            "train loss:2.245957509016211\n",
            "train loss:2.2356204897235705\n",
            "train loss:2.2436679436909177\n",
            "=== epoch:181, train acc:0.28, test acc:0.2361 ===\n",
            "train loss:2.23623123060504\n",
            "train loss:2.244166385977423\n",
            "train loss:2.246543846050823\n",
            "=== epoch:182, train acc:0.28, test acc:0.2349 ===\n",
            "train loss:2.2521997963545464\n",
            "train loss:2.265670062601178\n",
            "train loss:2.2462231746851398\n",
            "=== epoch:183, train acc:0.28, test acc:0.2375 ===\n",
            "train loss:2.2642636703694596\n",
            "train loss:2.2521730049604267\n",
            "train loss:2.235003374950083\n",
            "=== epoch:184, train acc:0.28, test acc:0.2384 ===\n",
            "train loss:2.2263334007350624\n",
            "train loss:2.232048308110093\n",
            "train loss:2.2296106358989274\n",
            "=== epoch:185, train acc:0.2833333333333333, test acc:0.2371 ===\n",
            "train loss:2.237724831659369\n",
            "train loss:2.221889133314159\n",
            "train loss:2.2581234943769926\n",
            "=== epoch:186, train acc:0.28, test acc:0.2366 ===\n",
            "train loss:2.2437492376481614\n",
            "train loss:2.242064349416255\n",
            "train loss:2.2515655629529014\n",
            "=== epoch:187, train acc:0.28, test acc:0.2364 ===\n",
            "train loss:2.2226319867654727\n",
            "train loss:2.2468194467105453\n",
            "train loss:2.24603956436033\n",
            "=== epoch:188, train acc:0.2833333333333333, test acc:0.2355 ===\n",
            "train loss:2.2496505706265792\n",
            "train loss:2.240241746400408\n",
            "train loss:2.2501447726652133\n",
            "=== epoch:189, train acc:0.2966666666666667, test acc:0.2384 ===\n",
            "train loss:2.2496743223265767\n",
            "train loss:2.2333901396525055\n",
            "train loss:2.2330791312113747\n",
            "=== epoch:190, train acc:0.3, test acc:0.2415 ===\n",
            "train loss:2.24986329224819\n",
            "train loss:2.233265138950392\n",
            "train loss:2.2304803946334846\n",
            "=== epoch:191, train acc:0.2966666666666667, test acc:0.2419 ===\n",
            "train loss:2.2329011084409554\n",
            "train loss:2.2249182379369574\n",
            "train loss:2.248453799430371\n",
            "=== epoch:192, train acc:0.2966666666666667, test acc:0.2417 ===\n",
            "train loss:2.256086685992639\n",
            "train loss:2.2310892156421045\n",
            "train loss:2.2586351058946486\n",
            "=== epoch:193, train acc:0.3, test acc:0.2404 ===\n",
            "train loss:2.2328047897273255\n",
            "train loss:2.2296752527233337\n",
            "train loss:2.2063213141112974\n",
            "=== epoch:194, train acc:0.3, test acc:0.2421 ===\n",
            "train loss:2.2362582514971647\n",
            "train loss:2.216143886264839\n",
            "train loss:2.2677297297647154\n",
            "=== epoch:195, train acc:0.2966666666666667, test acc:0.2442 ===\n",
            "train loss:2.2428069014212024\n",
            "train loss:2.2476407665135767\n",
            "train loss:2.2244409676243\n",
            "=== epoch:196, train acc:0.2966666666666667, test acc:0.2462 ===\n",
            "train loss:2.239073834831247\n",
            "train loss:2.2586768247799327\n",
            "train loss:2.2412850571570284\n",
            "=== epoch:197, train acc:0.30666666666666664, test acc:0.2484 ===\n",
            "train loss:2.2626616734200455\n",
            "train loss:2.2439264160290793\n",
            "train loss:2.2496447439560114\n",
            "=== epoch:198, train acc:0.30666666666666664, test acc:0.2494 ===\n",
            "train loss:2.2317609697727647\n",
            "train loss:2.240058650020819\n",
            "train loss:2.25213567684352\n",
            "=== epoch:199, train acc:0.31, test acc:0.2528 ===\n",
            "train loss:2.2119913339169575\n",
            "train loss:2.2167639651752054\n",
            "train loss:2.2182189613654253\n",
            "=== epoch:200, train acc:0.31, test acc:0.2522 ===\n",
            "train loss:2.241550668813582\n",
            "train loss:2.246408992059229\n",
            "train loss:2.243845956258753\n",
            "=== epoch:201, train acc:0.31, test acc:0.2543 ===\n",
            "train loss:2.2148021377527867\n",
            "train loss:2.245409958617222\n",
            "train loss:2.249374735563818\n",
            "=== epoch:202, train acc:0.31, test acc:0.2574 ===\n",
            "train loss:2.2250831139181466\n",
            "train loss:2.2313533094915607\n",
            "train loss:2.2215660018287293\n",
            "=== epoch:203, train acc:0.31, test acc:0.2548 ===\n",
            "train loss:2.216763294040237\n",
            "train loss:2.2285609828763104\n",
            "train loss:2.2424925710659593\n",
            "=== epoch:204, train acc:0.30666666666666664, test acc:0.2539 ===\n",
            "train loss:2.2365785713978568\n",
            "train loss:2.2193586158360827\n",
            "train loss:2.2808523787397648\n",
            "=== epoch:205, train acc:0.30666666666666664, test acc:0.255 ===\n",
            "train loss:2.210336619932\n",
            "train loss:2.255009796867031\n",
            "train loss:2.2271065123328886\n",
            "=== epoch:206, train acc:0.30333333333333334, test acc:0.252 ===\n",
            "train loss:2.22641308444519\n",
            "train loss:2.211699852644176\n",
            "train loss:2.2561250283593703\n",
            "=== epoch:207, train acc:0.30333333333333334, test acc:0.2529 ===\n",
            "train loss:2.2207895956090566\n",
            "train loss:2.2406977405979807\n",
            "train loss:2.244620432339663\n",
            "=== epoch:208, train acc:0.30333333333333334, test acc:0.2511 ===\n",
            "train loss:2.2295684091521606\n",
            "train loss:2.2439714252463108\n",
            "train loss:2.2211073217510178\n",
            "=== epoch:209, train acc:0.30333333333333334, test acc:0.2527 ===\n",
            "train loss:2.21056023230022\n",
            "train loss:2.2233709057556923\n",
            "train loss:2.236691122581562\n",
            "=== epoch:210, train acc:0.30333333333333334, test acc:0.2551 ===\n",
            "train loss:2.226422320493713\n",
            "train loss:2.2093973599208176\n",
            "train loss:2.2343562609502716\n",
            "=== epoch:211, train acc:0.30333333333333334, test acc:0.2566 ===\n",
            "train loss:2.2351825710978734\n",
            "train loss:2.228945329839602\n",
            "train loss:2.2283473539012486\n",
            "=== epoch:212, train acc:0.31, test acc:0.2574 ===\n",
            "train loss:2.2259076300696035\n",
            "train loss:2.2101576238152507\n",
            "train loss:2.22026043848515\n",
            "=== epoch:213, train acc:0.30333333333333334, test acc:0.2547 ===\n",
            "train loss:2.2185699904127345\n",
            "train loss:2.237366948621583\n",
            "train loss:2.2181363433055794\n",
            "=== epoch:214, train acc:0.30666666666666664, test acc:0.2564 ===\n",
            "train loss:2.230971382166233\n",
            "train loss:2.2169260436715463\n",
            "train loss:2.188500160875752\n",
            "=== epoch:215, train acc:0.30666666666666664, test acc:0.2571 ===\n",
            "train loss:2.222989107538886\n",
            "train loss:2.2366074005266956\n",
            "train loss:2.2179710238805077\n",
            "=== epoch:216, train acc:0.31333333333333335, test acc:0.2604 ===\n",
            "train loss:2.241242574432846\n",
            "train loss:2.242539143544501\n",
            "train loss:2.2479632773795917\n",
            "=== epoch:217, train acc:0.31666666666666665, test acc:0.2603 ===\n",
            "train loss:2.2227477585808355\n",
            "train loss:2.2272626335667245\n",
            "train loss:2.238558512722527\n",
            "=== epoch:218, train acc:0.31333333333333335, test acc:0.2608 ===\n",
            "train loss:2.2282480361290635\n",
            "train loss:2.2304958303122517\n",
            "train loss:2.217024113004425\n",
            "=== epoch:219, train acc:0.31666666666666665, test acc:0.2622 ===\n",
            "train loss:2.18389672097676\n",
            "train loss:2.212045952430781\n",
            "train loss:2.225185467555068\n",
            "=== epoch:220, train acc:0.30666666666666664, test acc:0.261 ===\n",
            "train loss:2.2364917924985304\n",
            "train loss:2.2313726910377816\n",
            "train loss:2.2120602837632832\n",
            "=== epoch:221, train acc:0.31, test acc:0.26 ===\n",
            "train loss:2.207867742412297\n",
            "train loss:2.2067783784133437\n",
            "train loss:2.1960358102745117\n",
            "=== epoch:222, train acc:0.31, test acc:0.2614 ===\n",
            "train loss:2.2366211456268035\n",
            "train loss:2.200948739523109\n",
            "train loss:2.1900843604708187\n",
            "=== epoch:223, train acc:0.31333333333333335, test acc:0.261 ===\n",
            "train loss:2.2016845789729307\n",
            "train loss:2.194185612072351\n",
            "train loss:2.2278511064885778\n",
            "=== epoch:224, train acc:0.32, test acc:0.2624 ===\n",
            "train loss:2.1993482374395743\n",
            "train loss:2.211882659370353\n",
            "train loss:2.2241780523556844\n",
            "=== epoch:225, train acc:0.31666666666666665, test acc:0.2638 ===\n",
            "train loss:2.235664045911919\n",
            "train loss:2.1957895692195244\n",
            "train loss:2.222733635282658\n",
            "=== epoch:226, train acc:0.3233333333333333, test acc:0.2657 ===\n",
            "train loss:2.232909278017094\n",
            "train loss:2.2235242095295957\n",
            "train loss:2.2140443939142953\n",
            "=== epoch:227, train acc:0.33, test acc:0.2686 ===\n",
            "train loss:2.213945255291986\n",
            "train loss:2.2080430256354906\n",
            "train loss:2.223991145816241\n",
            "=== epoch:228, train acc:0.3233333333333333, test acc:0.2664 ===\n",
            "train loss:2.2156050960383333\n",
            "train loss:2.2220925415778305\n",
            "train loss:2.238833859910801\n",
            "=== epoch:229, train acc:0.3333333333333333, test acc:0.2719 ===\n",
            "train loss:2.1966768938003383\n",
            "train loss:2.181366747767095\n",
            "train loss:2.185704615288007\n",
            "=== epoch:230, train acc:0.33, test acc:0.2752 ===\n",
            "train loss:2.2324325456158287\n",
            "train loss:2.18891188005616\n",
            "train loss:2.204075638512958\n",
            "=== epoch:231, train acc:0.33, test acc:0.2735 ===\n",
            "train loss:2.2170848643970342\n",
            "train loss:2.2243570877052257\n",
            "train loss:2.2364299342811504\n",
            "=== epoch:232, train acc:0.33666666666666667, test acc:0.2779 ===\n",
            "train loss:2.1978478741357925\n",
            "train loss:2.1896344589602026\n",
            "train loss:2.208802454781688\n",
            "=== epoch:233, train acc:0.34, test acc:0.2769 ===\n",
            "train loss:2.1972306627746305\n",
            "train loss:2.184357114284879\n",
            "train loss:2.2127417472377955\n",
            "=== epoch:234, train acc:0.34, test acc:0.2808 ===\n",
            "train loss:2.182512551841593\n",
            "train loss:2.1727542557904824\n",
            "train loss:2.2204284801269676\n",
            "=== epoch:235, train acc:0.3466666666666667, test acc:0.2831 ===\n",
            "train loss:2.2141462566154257\n",
            "train loss:2.2081414304481424\n",
            "train loss:2.2050295415528525\n",
            "=== epoch:236, train acc:0.3333333333333333, test acc:0.2817 ===\n",
            "train loss:2.202415736314318\n",
            "train loss:2.1975728034945696\n",
            "train loss:2.22096662786685\n",
            "=== epoch:237, train acc:0.34, test acc:0.2809 ===\n",
            "train loss:2.2121627233415952\n",
            "train loss:2.205650958871616\n",
            "train loss:2.173398365782171\n",
            "=== epoch:238, train acc:0.33666666666666667, test acc:0.2808 ===\n",
            "train loss:2.2049489770381108\n",
            "train loss:2.19540340570855\n",
            "train loss:2.1862263588008517\n",
            "=== epoch:239, train acc:0.34, test acc:0.2815 ===\n",
            "train loss:2.2178582961232025\n",
            "train loss:2.197597814005978\n",
            "train loss:2.219859582405913\n",
            "=== epoch:240, train acc:0.3433333333333333, test acc:0.2829 ===\n",
            "train loss:2.219123503410807\n",
            "train loss:2.212920675958826\n",
            "train loss:2.188034383063006\n",
            "=== epoch:241, train acc:0.3566666666666667, test acc:0.2873 ===\n",
            "train loss:2.214025694530575\n",
            "train loss:2.1800662372136568\n",
            "train loss:2.19862833722635\n",
            "=== epoch:242, train acc:0.3566666666666667, test acc:0.2885 ===\n",
            "train loss:2.1929009327259945\n",
            "train loss:2.1869647123412665\n",
            "train loss:2.1901459872692333\n",
            "=== epoch:243, train acc:0.36666666666666664, test acc:0.29 ===\n",
            "train loss:2.1876470014560976\n",
            "train loss:2.2059204890838924\n",
            "train loss:2.181578420815163\n",
            "=== epoch:244, train acc:0.35333333333333333, test acc:0.2881 ===\n",
            "train loss:2.2342331009277996\n",
            "train loss:2.2311530099562633\n",
            "train loss:2.204557113232558\n",
            "=== epoch:245, train acc:0.35333333333333333, test acc:0.2872 ===\n",
            "train loss:2.210225460321973\n",
            "train loss:2.205483325290272\n",
            "train loss:2.2073161249339854\n",
            "=== epoch:246, train acc:0.3566666666666667, test acc:0.289 ===\n",
            "train loss:2.1787538572349927\n",
            "train loss:2.1829000374301812\n",
            "train loss:2.199482026572716\n",
            "=== epoch:247, train acc:0.37, test acc:0.2949 ===\n",
            "train loss:2.182259107671967\n",
            "train loss:2.1844398671632437\n",
            "train loss:2.165022485316485\n",
            "=== epoch:248, train acc:0.37333333333333335, test acc:0.2963 ===\n",
            "train loss:2.1797910711843707\n",
            "train loss:2.1997768474418447\n",
            "train loss:2.1882305654828547\n",
            "=== epoch:249, train acc:0.36333333333333334, test acc:0.2947 ===\n",
            "train loss:2.191703246941908\n",
            "train loss:2.2086036386105086\n",
            "train loss:2.1969421091922268\n",
            "=== epoch:250, train acc:0.38, test acc:0.2965 ===\n",
            "train loss:2.231689269938363\n",
            "train loss:2.2103714189020014\n",
            "train loss:2.225263642473926\n",
            "=== epoch:251, train acc:0.38, test acc:0.2987 ===\n",
            "train loss:2.2185440215030523\n",
            "train loss:2.168773158067872\n",
            "train loss:2.157016513585446\n",
            "=== epoch:252, train acc:0.38, test acc:0.2959 ===\n",
            "train loss:2.198420059173887\n",
            "train loss:2.223359276787609\n",
            "train loss:2.222533634925333\n",
            "=== epoch:253, train acc:0.38333333333333336, test acc:0.2958 ===\n",
            "train loss:2.171822270629272\n",
            "train loss:2.1907331666808054\n",
            "train loss:2.2381070331610853\n",
            "=== epoch:254, train acc:0.38333333333333336, test acc:0.2968 ===\n",
            "train loss:2.2068624339006555\n",
            "train loss:2.173076429984473\n",
            "train loss:2.1873001556801994\n",
            "=== epoch:255, train acc:0.38666666666666666, test acc:0.2976 ===\n",
            "train loss:2.1751039458560277\n",
            "train loss:2.1780558161599366\n",
            "train loss:2.173880474881906\n",
            "=== epoch:256, train acc:0.38333333333333336, test acc:0.2973 ===\n",
            "train loss:2.178368183019511\n",
            "train loss:2.2008352196062226\n",
            "train loss:2.191168873954745\n",
            "=== epoch:257, train acc:0.38333333333333336, test acc:0.2995 ===\n",
            "train loss:2.1743643348044075\n",
            "train loss:2.1900692101516945\n",
            "train loss:2.1887463703246586\n",
            "=== epoch:258, train acc:0.38, test acc:0.2982 ===\n",
            "train loss:2.182557298840115\n",
            "train loss:2.1650316054511385\n",
            "train loss:2.191115579481484\n",
            "=== epoch:259, train acc:0.38, test acc:0.2989 ===\n",
            "train loss:2.1660211691473523\n",
            "train loss:2.176989454696942\n",
            "train loss:2.170264862347787\n",
            "=== epoch:260, train acc:0.37666666666666665, test acc:0.2982 ===\n",
            "train loss:2.149633349259485\n",
            "train loss:2.1750178377717004\n",
            "train loss:2.1773133958039557\n",
            "=== epoch:261, train acc:0.38333333333333336, test acc:0.3009 ===\n",
            "train loss:2.1886345258151536\n",
            "train loss:2.1626462293301003\n",
            "train loss:2.2121187040658974\n",
            "=== epoch:262, train acc:0.36333333333333334, test acc:0.2933 ===\n",
            "train loss:2.177380698505687\n",
            "train loss:2.162695328896351\n",
            "train loss:2.1960111161079823\n",
            "=== epoch:263, train acc:0.36333333333333334, test acc:0.2923 ===\n",
            "train loss:2.162333729646856\n",
            "train loss:2.180947997426152\n",
            "train loss:2.197092903952006\n",
            "=== epoch:264, train acc:0.36333333333333334, test acc:0.2919 ===\n",
            "train loss:2.1450728829424555\n",
            "train loss:2.1668766966542643\n",
            "train loss:2.168797741656672\n",
            "=== epoch:265, train acc:0.36666666666666664, test acc:0.2943 ===\n",
            "train loss:2.1571608516469403\n",
            "train loss:2.150564765191598\n",
            "train loss:2.181286640875147\n",
            "=== epoch:266, train acc:0.38, test acc:0.297 ===\n",
            "train loss:2.1895971002218717\n",
            "train loss:2.196382887839683\n",
            "train loss:2.193832954992449\n",
            "=== epoch:267, train acc:0.38, test acc:0.2988 ===\n",
            "train loss:2.1697313263175655\n",
            "train loss:2.169173671779404\n",
            "train loss:2.1924294160558944\n",
            "=== epoch:268, train acc:0.38666666666666666, test acc:0.3019 ===\n",
            "train loss:2.1308543095296586\n",
            "train loss:2.1471092973752963\n",
            "train loss:2.1500358521348004\n",
            "=== epoch:269, train acc:0.38333333333333336, test acc:0.3002 ===\n",
            "train loss:2.167021083099276\n",
            "train loss:2.1612358191939065\n",
            "train loss:2.1332271193244714\n",
            "=== epoch:270, train acc:0.39, test acc:0.3032 ===\n",
            "train loss:2.1693688048318287\n",
            "train loss:2.160806401779753\n",
            "train loss:2.194638580807036\n",
            "=== epoch:271, train acc:0.3933333333333333, test acc:0.3037 ===\n",
            "train loss:2.1793519838666304\n",
            "train loss:2.15542374306393\n",
            "train loss:2.1995882217388303\n",
            "=== epoch:272, train acc:0.3933333333333333, test acc:0.3055 ===\n",
            "train loss:2.1741765093639343\n",
            "train loss:2.143621238579864\n",
            "train loss:2.1201767334340853\n",
            "=== epoch:273, train acc:0.4066666666666667, test acc:0.3094 ===\n",
            "train loss:2.1477114050895274\n",
            "train loss:2.136125223352795\n",
            "train loss:2.183750095507571\n",
            "=== epoch:274, train acc:0.4, test acc:0.3099 ===\n",
            "train loss:2.146585114119927\n",
            "train loss:2.186767012915033\n",
            "train loss:2.1550818215580607\n",
            "=== epoch:275, train acc:0.4066666666666667, test acc:0.3127 ===\n",
            "train loss:2.2088943714981184\n",
            "train loss:2.181493087595672\n",
            "train loss:2.154068061814573\n",
            "=== epoch:276, train acc:0.4066666666666667, test acc:0.3158 ===\n",
            "train loss:2.18075897600865\n",
            "train loss:2.166948665048789\n",
            "train loss:2.1502793727821636\n",
            "=== epoch:277, train acc:0.41333333333333333, test acc:0.3154 ===\n",
            "train loss:2.152217419201163\n",
            "train loss:2.1380045319467014\n",
            "train loss:2.152845394864416\n",
            "=== epoch:278, train acc:0.4166666666666667, test acc:0.3158 ===\n",
            "train loss:2.131374994068825\n",
            "train loss:2.1373137177624297\n",
            "train loss:2.1646666668868493\n",
            "=== epoch:279, train acc:0.4166666666666667, test acc:0.3154 ===\n",
            "train loss:2.14077712182793\n",
            "train loss:2.1892686430413986\n",
            "train loss:2.1827796556517907\n",
            "=== epoch:280, train acc:0.4166666666666667, test acc:0.3156 ===\n",
            "train loss:2.1624832407253103\n",
            "train loss:2.1619514700926614\n",
            "train loss:2.1762609535068727\n",
            "=== epoch:281, train acc:0.4166666666666667, test acc:0.317 ===\n",
            "train loss:2.1294696470675603\n",
            "train loss:2.1494650052416775\n",
            "train loss:2.110932535716869\n",
            "=== epoch:282, train acc:0.41333333333333333, test acc:0.3174 ===\n",
            "train loss:2.1545769934996337\n",
            "train loss:2.1759270442684837\n",
            "train loss:2.1814351169411967\n",
            "=== epoch:283, train acc:0.41, test acc:0.3154 ===\n",
            "train loss:2.1883492186376357\n",
            "train loss:2.1148706775514134\n",
            "train loss:2.14123459493682\n",
            "=== epoch:284, train acc:0.4, test acc:0.3145 ===\n",
            "train loss:2.166634641402345\n",
            "train loss:2.1555492823076317\n",
            "train loss:2.2012993342673273\n",
            "=== epoch:285, train acc:0.41333333333333333, test acc:0.3168 ===\n",
            "train loss:2.1268966116877297\n",
            "train loss:2.1151471007193994\n",
            "train loss:2.1642659975349128\n",
            "=== epoch:286, train acc:0.4, test acc:0.3135 ===\n",
            "train loss:2.178940368266049\n",
            "train loss:2.122390244482734\n",
            "train loss:2.151538596232858\n",
            "=== epoch:287, train acc:0.4, test acc:0.3138 ===\n",
            "train loss:2.09813525105166\n",
            "train loss:2.179780012930909\n",
            "train loss:2.110761444646289\n",
            "=== epoch:288, train acc:0.4033333333333333, test acc:0.3152 ===\n",
            "train loss:2.111673943859028\n",
            "train loss:2.180040102869875\n",
            "train loss:2.1636706682100417\n",
            "=== epoch:289, train acc:0.4, test acc:0.316 ===\n",
            "train loss:2.1176435934562807\n",
            "train loss:2.129847646205944\n",
            "train loss:2.155587386180006\n",
            "=== epoch:290, train acc:0.4033333333333333, test acc:0.3165 ===\n",
            "train loss:2.126389416604667\n",
            "train loss:2.1471641969832085\n",
            "train loss:2.1586039685917258\n",
            "=== epoch:291, train acc:0.4066666666666667, test acc:0.3183 ===\n",
            "train loss:2.113815755929205\n",
            "train loss:2.139765941495563\n",
            "train loss:2.1468973847859165\n",
            "=== epoch:292, train acc:0.41, test acc:0.3202 ===\n",
            "train loss:2.165129723808136\n",
            "train loss:2.158238758127217\n",
            "train loss:2.163335708408147\n",
            "=== epoch:293, train acc:0.4166666666666667, test acc:0.3261 ===\n",
            "train loss:2.127307468542766\n",
            "train loss:2.1378275782599734\n",
            "train loss:2.1292820494719518\n",
            "=== epoch:294, train acc:0.42333333333333334, test acc:0.328 ===\n",
            "train loss:2.177110677903192\n",
            "train loss:2.164440428775723\n",
            "train loss:2.155403112279515\n",
            "=== epoch:295, train acc:0.4266666666666667, test acc:0.3269 ===\n",
            "train loss:2.1307572018688656\n",
            "train loss:2.1383170150295667\n",
            "train loss:2.1331743391999503\n",
            "=== epoch:296, train acc:0.42, test acc:0.3286 ===\n",
            "train loss:2.1233073681598436\n",
            "train loss:2.1251418898107644\n",
            "train loss:2.106919387670136\n",
            "=== epoch:297, train acc:0.42, test acc:0.3273 ===\n",
            "train loss:2.114109950474142\n",
            "train loss:2.142262556553561\n",
            "train loss:2.1072426029647207\n",
            "=== epoch:298, train acc:0.42, test acc:0.3275 ===\n",
            "train loss:2.1240008904132965\n",
            "train loss:2.1840315608632226\n",
            "train loss:2.1719736334206146\n",
            "=== epoch:299, train acc:0.4266666666666667, test acc:0.3295 ===\n",
            "train loss:2.1862544938848223\n",
            "train loss:2.089448819612879\n",
            "train loss:2.1559258823847696\n",
            "=== epoch:300, train acc:0.4266666666666667, test acc:0.3318 ===\n",
            "train loss:2.166497724096408\n",
            "train loss:2.102498186515803\n",
            "train loss:2.106086057496456\n",
            "=== epoch:301, train acc:0.4266666666666667, test acc:0.3325 ===\n",
            "train loss:2.076747600086616\n",
            "train loss:2.161999769163445\n",
            "=============== Final Test Accuracy ===============\n",
            "test acc:0.3333\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUylJREFUeJzt3Qd4U1X/B/Bv96BQRksLpVD23nuJyhIUBUUBFRAV/7heBfEFVFAc4EJBQXkdgBsUARWQvQQqe0OBslqgLS2lm+78n98JKR1pmyZtk958P88T29zcm9xe0+bLOb9zjoNOp9OBiIiISCMcrX0CRERERKWJ4YaIiIg0heGGiIiINIXhhoiIiDSF4YaIiIg0heGGiIiINIXhhoiIiDSF4YaIiIg0heGGiIiINIXhhoiIiDTFquFmx44dGDJkCGrXrg0HBwesWrWq2GO2bduGDh06wM3NDY0aNcKSJUvK5VyJiIioYrBquElOTkbbtm2xYMECk/a/cOEC7r33Xtx11104fPgwXn75ZTz99NNYv359mZ8rERERVQwOtrJwprTcrFy5EkOHDi10nylTpmDNmjU4fvx4zraRI0ciLi4O69atK6czJSIiIlvmjAokODgY/fr1y7Nt4MCBqgWnMGlpaepmkJ2djdjYWNSoUUMFKiIiIrJ90haTmJioSlkcHR21E24iIyPh5+eXZ5vcT0hIwM2bN+Hh4VHgmNmzZ2PmzJnleJZERERUVsLDw1GnTh3thBtzTJs2DZMmTcq5Hx8fj7p166qLU6VKFaueGxEREZlGGjICAwNRuXLlYvetUOHG398fUVFRebbJfQkpxlpthIyqklt+cgzDDRERUcViSklJhZrnpnv37ti8eXOebRs3blTbiYiIiKwebpKSktSQbrkZhnrL92FhYTldSmPGjMnZf8KECTh//jz++9//IiQkBF988QV+/fVXTJw40Wo/AxEREdkWq4ab/fv3o3379uompDZGvp8xY4a6HxERkRN0RP369dVQcGmtkflx5syZg2+++UaNmCIiIiKyqXluyrMgydvbWxUWs+aGiIhIe5/fFarmhoiIiKg4DDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpClWDzcLFixAUFAQ3N3d0bVrV+zdu7fI/efOnYumTZvCw8MDgYGBmDhxIlJTU8vtfImIiMi2WTXcLFu2DJMmTcKbb76JgwcPom3bthg4cCCuXbtmdP+ff/4ZU6dOVfufOnUK3377rXqO1157rdzPnYiIiGyTVcPNJ598gvHjx2PcuHFo0aIFFi5cCE9PTyxatMjo/rt370bPnj3x6KOPqtaeAQMGYNSoUcW29hAREZH9sFq4SU9Px4EDB9CvX7/bJ+PoqO4HBwcbPaZHjx7qGEOYOX/+PNauXYvBgwcX+jppaWlISEjIcyMiIiLtcrbWC8fExCArKwt+fn55tsv9kJAQo8dIi40c16tXL+h0OmRmZmLChAlFdkvNnj0bM2fOLPXzJyIiIttk9YLikti2bRtmzZqFL774QtXorFixAmvWrME777xT6DHTpk1DfHx8zi08PLxcz5mIiIjspOXGx8cHTk5OiIqKyrNd7vv7+xs9Zvr06Rg9ejSefvppdb9169ZITk7GM888g9dff111a+Xn5uambkRERGQfrNZy4+rqio4dO2Lz5s0527Kzs9X97t27Gz0mJSWlQICRgCSkm4qIiIjIai03QoaBjx07Fp06dUKXLl3UHDbSEiOjp8SYMWMQEBCg6mbEkCFD1Air9u3bqzlxQkNDVWuObDeEHCIiIrJvVg03I0aMQHR0NGbMmIHIyEi0a9cO69atyykyDgsLy9NS88Ybb8DBwUF9vXLlCnx9fVWwee+996z4UxAREZEtcdDZWX+ODAX39vZWxcVVqlSx9ukQERFRKX9+V6jRUkRERETFYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk2xerhZsGABgoKC4O7ujq5du2Lv3r1F7h8XF4fnn38etWrVgpubG5o0aYK1a9eW2/kSERGRbXO25osvW7YMkyZNwsKFC1WwmTt3LgYOHIjTp0+jZs2aBfZPT09H//791WPLly9HQEAALl26hKpVq1rl/ImIiMj2OOh0Op21XlwCTefOnTF//nx1Pzs7G4GBgXjxxRcxderUAvtLCProo48QEhICFxcXs14zISEB3t7eiI+PR5UqVSz+GYiIiKjsleTz22rdUtIKc+DAAfTr1+/2yTg6qvvBwcFGj/nzzz/RvXt31S3l5+eHVq1aYdasWcjKyir0ddLS0tQFyX0jIiIi7bJauImJiVGhREJKbnI/MjLS6DHnz59X3VFynNTZTJ8+HXPmzMG7775b6OvMnj1bJT3DTVqGiIiISLusXlBcEtJtJfU2X331FTp27IgRI0bg9ddfV91VhZk2bZpqwjLcwsPDy/WciYiIyE4Kin18fODk5ISoqKg82+W+v7+/0WNkhJTU2shxBs2bN1ctPdLN5erqWuAYGVElNyIiIrIPVmu5kSAirS+bN2/O0zIj96WuxpiePXsiNDRU7Wdw5swZFXqMBRsiIiKyP1btlpJh4F9//TW+++47nDp1Cs8++yySk5Mxbtw49fiYMWNUt5KBPB4bG4uXXnpJhZo1a9aogmIpMCYiIiKy+jw3UjMTHR2NGTNmqK6ldu3aYd26dTlFxmFhYWoElYEUA69fvx4TJ05EmzZt1Dw3EnSmTJlixZ+CiIiIbIlV57mxBs5zQ0REVPFUiHluiIiIiMqCWeFm69atpX8mRERERNYKN/fccw8aNmyoJs/jvDFERERU4cPNlStX8MILL6jZghs0aKAWu/z111/VXDNEREREFS7cyAR8MmLp8OHD2LNnD5o0aYLnnnsOtWvXxn/+8x8cOXKk9M+UiIiIyAQWFxR36NBBzUUjLTlJSUlYtGiRmpyvd+/eOHHihKVPT0RERFQ+4SYjI0N1Sw0ePBj16tVT88/Mnz9fLZ8gswjLtocfftjcpyciIiIqv3luXnzxRfzyyy+QQ0ePHo2nn34arVq1yrOPTMon3VS5l0qwBZznhoiIqOIpyee3WTMUnzx5Ep9//jkefPDBQhellLocDhknIiKi8sYZiomIiMjmlfkMxbNnz1aFw/nJtg8++MCcpyQiIiIqFWaFm//9739o1qxZge0tW7bEwoULS+O8iIiIiMov3EixcK1atQps9/X1RUREhHlnQkRERGStcBMYGIhdu3YV2C7bZIQUERERkbWYNVpq/PjxePnll9VcN3fffbfatnnzZvz3v//FK6+8UtrnSERERFS24ebVV1/F9evX1ZILhvWk3N3dMWXKFDVbMREREVGFHAouyy2cOnUKHh4eaNy4caFz3tgSDgUnIiKqeMp8Ej8DLy8vdO7c2ZKnICIiIipVZoeb/fv349dff0VYWFhO15TBihUrSuPciIiIiMpntNTSpUvRo0cP1SW1cuVKVVgsK4Bv2bJFNRkRERERVahwM2vWLHz66af466+/4Orqinnz5iEkJASPPPII6tatW/pnSURERFSW4ebcuXO499571fcSbpKTk+Hg4ICJEyfiq6++MucpiYiIiKwXbqpVq4bExET1fUBAAI4fP66+j4uLQ0pKSumcGREREVF5FRTfcccd2LhxI1q3bo2HH34YL730kqq3kW19+/Y15ymJiIiIrBdu5s+fj9TUVPX966+/DhcXF+zevRsPPfQQ3njjjdI5MyIiIqLyCDeZmZlYvXo1Bg4cqO47Ojpi6tSp5rw2ERERkfVrbpydnTFhwoSclhsiIiKiCl9Q3KVLFxw+fLj0z4aIiIjIGjU3smDmpEmTEB4ejo4dO6JSpUp5Hm/Tpo2l50VERERUfgtnSp1NgSdycIA8lXzNysqCreLCmURERBVPmS+ceeHCBXPPjYiIiKhMmRVu6tWrV/pnQkRERGStcPP9998X+fiYMWPMPR8iIiKi8q+5keUXcpNVwWXZBVlnytPTE7GxsbBVrLkhIiKqeEry+W3WUPAbN27kuSUlJeH06dPo1asXfvnlF3PPm4iIiMhiZoUbYxo3boz3339frTNFREREVOHDjWH24qtXr5bmUxIRERGVfUHxn3/+mee+lO1ERESoBTV79uxpzlMSERERWS/cDB06NM99mbjP19cXd999N+bMmVM6Z0ZERERUXuEmOzvbnMOIiIiIKlbNDREREVGFDDcPPfQQPvjggwLbP/zwQzz88MOlcV5ERERE5RduduzYgcGDBxfYPmjQIPUYERERUYUKNzJpn8xGnJ+Li4uaQZCIiIioQoWb1q1bY9myZQW2L126FC1atCiN8yIiIiIqv9FS06dPx4MPPohz586p4d9i8+bNaumF3377zbwzISIiIrJWuBkyZAhWrVqFWbNmYfny5fDw8ECbNm2wadMm9OnTpzTOi4iIiKj8VgWvyLgqOBERUcVT5quC79u3D3v27CmwXbbt37/fnKckIiIiKhVmhZvnn38e4eHhBbZfuXJFPUZERERUocLNyZMn0aFDhwLb27dvrx4jIiIiqlDhxs3NDVFRUQW2y8rgzs5m1SgTERERWS/cDBgwANOmTVNFPQZxcXF47bXX0L9//9I5MyIiIqpQsrJ1CD53HX8cvqK+yn1rMKuZ5eOPP8Ydd9yBevXqqa4ocfjwYfj5+eGHH34o7XMkIiIiG7fueARm/nUSEfGpOdtqebvjzSEtcE+rWhVjKHhycjJ++uknHDlyJGeem1GjRqklGGwZh4ITERGVfrB59seDyB8oHG59/fLxDhYHnJJ8fls0z40UD4eFhSE9PT3P9vvvvx+2iuGGiIio9EjXU8/3tyAy4XaLTf6A4+/tjp1T7oaToyHulO3nt1ndUufPn8ewYcNw7NgxODg4QPKRfDXIysoy52mJiIiolALH3guxuJaYipqV3dGlfnWLgoVYczQCb68+gYc7BmLywKY525cfCC802AhpQZGuKjmf7g1roDyYFW5eeukl1K9fX60nJV9l8r7Y2Fi88sorqh6HiIiItFP78tWOc5i1NkR9P39rKO5q5ouO9aojO1uHL7aeM+k5JGiVF7PCTXBwMLZs2QIfHx84OjrCyckJvXr1wuzZs/Gf//wHhw4dKv0zJSIiIrNqXyLjU9V2c2pfTkUk4IN1p9X3DXwq4XxMMib/dhR9m9VULTaXYlNMeh5pQbLpoeDS7VS5cmX1vQScq1evqu9l9NTp0/oLQEREROUjOjENa49GYOqKYwWCjTBskxad4oZn5x7OvTs0Bq+vPKa2DWrlj9+f7YFqni64EJOMb3ZewOqjEeqYyu7OOcXD+TncajmSrjGbbrlp1aqVGiUlXVJdu3bFhx9+CFdXV3z11Vdo0KBB6Z8lERERGbX9TDRe+PkgElMzi9xPZ0Lti7EuLeHq7Ijp97VAtUquWDyuC9afiIRhOJJfFTf4VXbH8z8fVEEmd3QyBB7pErO05qfMw80bb7yhhoKLt99+G/fddx969+6NGjVqYNmyZaV9jkRERGTEjjPRGLd4L6QxxsfLFTFJeUcvGzNm0R783x0N8xQFF9WlJdIzs3H0chxqV/VAu8Cq6pbfl44dCgQj/4o2z01+UlBcrVq1PKOmbBGHghMRkRakZmSh/6fbER57E0Pa1sbDHQMwZtE+k46t6umC/a/3g7OTvjpFup16fbClQItNSYdzl8UoLXM+v82quTGmevXqZgebBQsWICgoCO7u7qqba+/evSYdt3TpUvWaQ4cONet1iYiIKoKU9Ex8sC5EFffG38zAzL9O4InFe1Ww8a/ijtkPtkbPRr6qtsWhiOcx5Iy4lAwcuHQjZ7sEksKCTf4uraJIkJEurwfaBaiv5dkVlZvVV7mUbqxJkyZh4cKFKtjMnTsXAwcOVIXJNWvWLPS4ixcvYvLkyao7jIiISGtyt4L8e+46ftkXjj8PX0XHetXw5xH9QB4xY0gLeLnpP86lC+jZHwvWvhjkriXedCoKXRvUQHhsCv45G21zw7ltolvKXBJoOnfujPnz56v72dnZCAwMxIsvvoipU6cWOlpL1rZ68skn8c8//6hFO1etWmXS67FbioiIbF1hhb25/efuRmjqXwX3tqlV7LFebs5IStMXHFdxd0ZCaibq1fDExH5N8NrKY0hJN23y3V/Gdyu3ifjKfYbi0iLLNhw4cECtMG4g8+b069dPzaVTGClilladp556SoWboqSlpalb7otDRERkq4oq7DUY1SUQkwbkLQg2uKdVLfRv4Z+n9iWgmgfu/Girarl5uV8TvP93CC5dT8HLyw6bdE6GmpvyHM5tCauGm5iYGNUKI6uJ5yb3Q0L0MyHmt3PnTnz77bdqFXJTyMSCM2fOLJXzJSIiKuuuKGl1KSrYuDo54JX+xoNN/tqX3J67sxH2XYzF8E51cD05DT/vCVP7PdSxDro3qIHXVhzD1fhUmxnOXaFrbkoiMTERo0ePxtdff60mDzSFtApJTU/ulhvp9iIiIiprJR09VFxhr0jP0uHstST4VHYr0blMzjX0+9WBzdQtt93T+hrt0rLWcO4KG24koMjSDVFRUXm2y31/f/8C+587d04VEg8ZMiRnm9ToCGdnZ1WE3LBhwzzHuLm5qRsREZE5zB3ebM4aT6YW7JZVYe89Rrq0SnM4t12EG5nVuGPHjmoBTsNwbgkrcv+FF14osH+zZs3USuT5JxSUFp158+axRYaIiEpVUQFlYEt/VbcSWN2zwIe/OWs8Jadlwt3Z0errNDkZ6dKqaKzeLSVdRmPHjkWnTp3QpUsXNRRcZj8eN26cenzMmDEICAhQtTMyD44s/ZBb1ar6WRLzbyciIrJEcQGlU1A17Lt4Ax3qVsXC0R1zAkdRdTOyTWKQPC4tJIZQdDM9Cw8s2IXz0UlwdnRAZiHrP1W0wl67DTcjRoxAdHQ0ZsyYgcjISLRr1w7r1q3LKTIOCwtTI6iIiIjKS3EBRUiwEQfD4tDlvc1wdXLEmO71cGdTX5MnxDO0kHyxLRSh15LU99mFzNBSEQt77Xaem/LGeW6IiKg4sir2qK//LXa/CX0aYmvINZyOSszZVrOyG64l3p6CpDDzRrbD9aR0rD0WgSOX45CRpVPLKGw6GYW7mtXEobAbJarX0bqEijLPDRERkS0ytWC3ea3KmHJPU8Qmp2PPhVhM/u2IScHGMLHeK78eyemCuqupLz4b2U61GsmaT2W5TpPWMdwQERHlcjXupgoWppDQIWsc1vByw+DWtdChbjUcvHQDk5cfKXTWX0PdTFJqpgo2MlPw9HtbqC4qeS5nJwfNFPZaC8MNERHRLdJFJK0p2bpsuLs4IjVDP92IqYW9sm1wm1qQUtEJPx40epyQ7qW/j0eq7+9p5Y9+LfJOZkuWYaUuERERgC0hUXjup4O4mZGFtExdkcGmuMJeqYtZ+HgHVSeTP/zIMPC+zf1UrY7o35zBprSx5YaIiDQvd/1KWkY2Vhy8rNZmyt3ysnRvuPraxM8LZ6L0I5eEb2U3ROeqozF1xl7DhHhzN53B51tC0dC3EjZM7KMCkbQQyeKV1Su5on3damXyM9szhhsiIrLLFbZn/HEM617uo75PzcjCP2dj1PcfDm+Lp7/bh5ikdNSp5oHtr95ldmGvWrupQx0VbsJjb6r1m9KzsvHXkavq8fva1GKRcBlguCEiIrtcYTskMgm/H7yswsfuczGqO6q2tzva1vHGiM6BWLD1HHo18rG4sFcKhn28XFVYWrZf3zok7m9bG68Nbm7281LhGG6IiMhuV9h+Z/VJDG0XgI0n9WscSmGvjFh6qW8T1PfxQt9mNS0+D3m+RU90zmkZEvV9KmFQK3/1GJU+hhsiItIkU1bYjkvJwC97w7DmaIS63+9Wca+rsyOGd6xTaufSpk5VdaPywXBDRER2PRHfjD+OQ6a1aV6rCro14LwyWsCh4EREpEmmrpwtwUa6n379v26qxYYqPrbcEBFRhSYjndYdj0Tf5jVR2d0lZ7uMapJ5ZgrrmpJqFx8vNyx9phsa+FZi/YuGMKISEVGFJsOrX152GHM2nMmzXUY5yXw0xhhizDtDW6JhTS8GG41hyw0REVVY/56/jhWHrqjv/z4eocJM7qBSyc1ZdTWlZ+adbdjUifjIRHHhQMr1wh/3rAFUDUR5YbghIqKKNctwQir2XYrFqkNXkJR2e3HKqIQ0zN8SquaSebhjILzcnfHempOqpqZr/Wr4T98miElK4wrbZRFs5ncEMotYDd3ZDXjhQLkFHIYbIiKqsLMMi4CqHmremJ2hMZizUd819emm211UMqT7vWGt4ObsVK7nbDekxaaoYCPkcdmP4YaIiOxdXEo63l19EssP6ruejJk6qJnqdpJwI2pWdlPz12RmZ6sZgJ/qVZ81NXaG4YaIiGxKdrYOR6/Eo02AN2b/HVJksJHIMmvtKfz5Qi84OzogM1uHjx9uq5Y8kMDT2K9yuZ472QaGGyIisimz/z6Fr/+5gEc61cGqQ/oFJgsjSytIV1XotST8b3RHJKdn4Y4mvuV2rnZRFKzLBi7u1D8W1As4txWIuwQ0uBOo5AMc/AG2huGGiIhsxomr8fh25wX1/a/7L5doNuIH2gWU4ZlpfNRSnAlFwWLX3Nvfh6yGrWK4ISIim+mOemOVfikEN2dHpOUbvl0asxFrmiWjllJMKAoWXv5A7XZAnU7AhR1AVibgWgkI3QhbwnBDRGSvQ6oTU8t1WHRhr/vnkauqPiYjKxuHwuJQydUJvzzTDWMW7QV0Ori5OOFaQprR1b0dbs1ZI89l98pj1NKjy/ThRtzxqv7r1cMMN0REZFtDqmuVwYR2N9OzsO9irAodOh2wYOtZLD9wGZEJaXled0SnQMzdfFbdN+Srif2bqBW0N07sAx10OHjpBp798aAKMrkDjiGOybnb7Zw12VmAo5M0e+m/N8X5bYBXTaBK7dI5B+nqkhah4lqMZL9y4qDTydvOfiQkJMDb2xvx8fGoUqWKtU+HiKhcg42EhPx/9A2x4MvHO5RKwAmPTcH47/cjJDIRrQO8EZuchitxBeenyR9WRDP/ylj9Yi84OzlaJZRVmLqZrHRg1XNA+B7AoyqQlgRkZ5j+Gh7VgXvnAA6OQMgafeBJvlb8cc9sv91yU9JztnCOm5J8fjPcEBHZAekS6vXBliIXkZTunZ1T7i6yFaS4Lq0byekYMHcHohNNqN+4RQ7/enQnrD8ZiWfuaIhGNb3Mem27qZtxdAacXIGMFDNfxFGafMw7tLBwY2Of3+yWIiKyA3svXC802OQeUi3hoXtD490HxlpP3F0c8cnD7TC4jb715IN1ISrYyCrbHzzUBm+sPIbTUUlFnpsUEHu6OePD4W2L3E+CTGHnViYsaY0w91hT6mayM/W3ej31rS/SRuFWGbgeCvwwFMUaswo49ScQuhlw9wbqdgN8mwGrX4ZWMNwQEVVAprZinIpIwP+2n8OxK/EmPe87q0+gdUBVjL+jQZ4WlMK6tFIzsvHczwfxwMnaSMvIxroTkWq7BJvOQdXx3F2N8NLSw8W+rvwcmhl5VB5rLXV6Ehj8sb7exqCoMJWbBBoJRblJUbCGMNwQEVUwJak/efOPE9h7Mdbk5z4Zkahua49FYMKdDeHp6oRsnQ7zNp01OlrJ4I/Dtyfbe7hjHRVsSjJE2+aGclsy8qg8Ri11GJs32GiwKNgSDDdERBVIYS0okfGpmPDjQUwb1Ayju9eDp6szzkQlqmAjLTqyfeH2c7ielF7okOrqlVzxYt9GWHssUrUKfbT+dInObWTnQHSoWw1D2t4ehSMtShK85Pw4lLsIN+OAtZOBiCPWCShVA/UtSWVcFFxeGG6IiCpQV5S02BgLCYZtshbTVzvO4X+jO2H10Qi1rX9zPzzduwHqVPMocki1rJwtLT+PdqmHr/85r0Y7iSs3UnAwLK7Y85N6mPyzBEuwkhYlzQ7lDt8LpMYDp9cCR5cB1RuWvHUjdBOwepJ+SQNLWBpQqgZWmPBSHIYbIrIZdjEaxgJybYoqCja4npyB4QuDc+4/1q2u+irBRYZ75+/S8s/XpeXq7Ijn72qU83jwuesY9fW/Znctmfq6ZaIkhb0yV8yJFcCJlUCyifUrf9+ayM7gyn7Tz+3GRWDLu7cnwKtaD2g8ANj3NcymoYBiCYYbIrIJls5jYuvBaHdoDH7dH45pg5vDr4p59SWmFt22C6yKw+H6lhaZZ6ZnQ5+cx+Ra9m/hX6JrVRpdS+a8rsVKWti7+S1g17ySvYYEEnmOSjWB7s8DiRFA1HFg/6Lij/1tnH5ItqML0OUZoM9/9YHHknBDCsMNEdl0HYlsL2pyudBriVi08wK2hFwrMPtteUzwZkqoiktJx4u/HML15HQkpWXim7GdTT42N1OnJZtyTzM10ik9Kxt+ld3gmO85SzqkurS6lsp9KHdJCnvjwoBdn+m39fgPkJoAHFxS/Gs88n3BeV9k5JEp4UaCTbP7gP5vAzUa6jelaauw11oYbojIputI5ONSHu/d2BfXEtNQ36fS7cd1Ooz+Zi8iEgq2aJgSjHKfgzktCsW1NqVmZKm1kpbtC1PBRmw6dQ0bT0YhKzu7xC1V0Un65yhM7haU0m4RsWrXUlnb/gFwcaf+Hdd+NDDgHX1AMSXcWOK+T/VDujVc2GstDDdEZNN1JIbJ5YZ9sQtnopIwrmcQJg9oqlaNVscaCTb5g5F0hxT2YW9ud1hxrU1v3t8CP+8JU+dscGdTX2w7HY0py4/iRkrBUUv5A5mskp271WXLqdvT41ujONcqXUvlQYqBRa12wMBZlo88MvXYRv2NP8a6GYtx+QUisqo/Dl8xaZK3/Lw9XNQtLLb4Keh/Gd/NaHeIuWstFbeUQf7zrF3VA4Nb+eOp3vXRb852XC3iOHltP2939G7kg7+PR+KVAU3wRI8g7L90AyO/+le99jsPtMIX20LtY52l4oqC05OB478D57YAfi2BpoOBWm31E9WF7QZWPFP887d+GGg1XF/M6+ho3RmKqVBcW6oIDDdEtkUKbR/9Zo9J+z7Qrja2n4lGXEoJFggEMLpbXRUE3hvWOqeY15K1loLPxWDU18WfsywC+d2TXfIUEH+++SzmbDxTovOX+plL15ORkaVDr0Y++PHprjZfQF2uRcGWsuJ6SWQ6ri1FRGVm38VYnLgSj7E9guDgUPDDtCQfummZWViy+4JJr9uiVmV88kg7VWeTmpmtQsL/dpw36dile8ORka2Di9MJfPl4R1ULI8sMmLPWkpyzzNZrimfvbFhgZFTd6p4mHevh4oQRnQPxffBFhF7Td23d27oWPnq4jXWKc63FlKJgcdfrQGYqcCkYiD4FZNwEnN2B1OLn5yHtYbghomLJSs9X4m7Ct7Ibxi3ep0b81K3hibub+VlUv7JgSyg2nLwGZ0cHZMrqiUWQVhd9SHKAl5OjGlI9rH0Axi7ei2sJaUUuDSDBRkg3z5fbzqnzPHLZtLWWZN/oJP2HqwSr74Mv4cClGyYda2zel5omDgP/bGQ79G/pr7qkLsWmqO6ttnW8jQZKgr5Lydiopa/6WOuMyIoYboioSDfTszD0i124dD0FAVU9VLARMuLHEG5kn22nr+G5n4oezj2wpb9aaNHD1QkXYpKxcLu+5WXuyHYq4OQPRgaPdq2L9nWrFdjerFYVzLy/ZaFDlA33XZwc0K+5nwo3smq1YZt08xTnu+BL6pabl5sTXJyc1BDvks77YuqcMXc311/bIJ9K6ma3Io6af6zG1ksi0zHcEFGRXUtbQ66pYCOk9cZAhjS/l63Dd8EXMWvNKdWiUNSyAP9dflStbSRT+q9+sTfe//uUmoelTxNf1d0ix+cfiROTmIYdZ6PVvC3mDFGW4/49fx1dG1THgBb+KlRJqKjh5YZJ/Zqo0BZ/s/D6HVcnR3SsVzVPa0m1Sq54pX8TtW6TOfO+aH45gtIoro0+Axz5GajXC9j0pvmvy2HVdosFxURGHLscj9dWHsPILoF4rGs9+yneLKRrSfRtVhPnY5LxYPsAVesiLTi9G/vgn7MxJX4Nw5BosfmVPmjo62XxeZvz/8gwWgqFhIzi5sixZFZlS2dkLnfmjv4pySzBlXyBA4uBTTOBzNtB2iQsCta8BI6WKhzDDZni5aWHsOrwVfX9Xc18ERKRmOdDSOof+rfww0fD22iqBqKwodHCIdeH/fM/H8SaW4sySn7o27wmNp68PQdLYeS65W4puaOJL75/sgvsddmHcg/N5RFQ8h9vat1Lm5HA+a1AUpT+vk9TIObMrW4lE5adYLjRvASOliIyX0ZWtprK32BriL6FITf5gF5+4DLqVffEi30bwxaZ+sF5PjoJu85dV+Hls81niyzMNUyIN6iVvwo3ld2d8fmo9nBzdjIp3Cx4tD1m/HFCtQCJx7rqF3S0JksnprNk1FK5jniyJKCUZBkD7zrAkV+AqBNSgQ1EHjPt/I4u1X+tUgfoPRHo+KR+leyY08DPI0x7DqJbGG6I8tl/8QYSUjNR1cMZKelZSC+i6FQmUhvXsz6ydDrVKmErTG2NyMzKxuhv9+appTFlaPTgVrUw/1H9Ao11qnmqIGVKkWz3hj4Y1aUu3lt7Cn5V3FRXly2wi2HVJQko5tagSEvLzk+Bk6tKfmz9PkDnp4AmgwBnV/226vUBR2cWBVOJMdwQ5bPplL5ZvE2dqthRTD3JzYxs9Hh/C6Rnasd/7zIacMq766Eki1BKC5UEG2mB8XR1QlSuhScLIz+HLAlwX5vaZhXJju5eT62zJIXEzk65ZoMl23B2k757SGbtlVaYklgxXv9VVrnu+ATg4q5vvQmeX/yxsniksW4lFgWTGRhuiHK5lpCKtcf0tSSNa3oVG25EQqq+hkQCjNThWKueQ0bv/N8P+xGbnFHkIpRv/XkCfx25inPRyXB2csgZat2jYQ2MXbTPrLlbSrKworuLE6YOKnz0ExWjrKf13/qO/uvOufqlDBKvAv76iQOL5VYZqN0BuOs1oG632zU3poSbonCtJSohhhuiW46Ex+H/fjiAyIRU+Hi5oVdjX3y766LJx+85fz1PuCmsBUU++Cf8eBDtA6uisocLGvhUUusHVXZ3sWxCvK2huBBT9DpLci6RCWlYcywyz/ZHu9RV3UumdC0Zm7tF8wsr2gpz6mak5UTqX/Z+Zdpr1Gikn9k36rh+OLY4v820Y8f8BQS0N21fojLEcEN2K/jcdbWUgEhOz8SSXReRlpmt1vH5ZkwnBFbXf9gXtfaQ1I3IXCoTfz2Cvbeey9DiIsGkqOLcQ+H6aeF3nInGztAY3N+2Nhr4VlJzvqw/EVlkMPrysQ5qccWdZ2NU60uPhj74O19gKYp0n7Wp462Gcd/V1Bf1augniSuN+Vfson7FWosqlrSwVxaT3PIucFU/3N0kD30L1GwB7P8WSLoGeFYHDiwBrocWf6yGRg5SxcZwQ3ZJupKeWLxXhZnc7m5WE/NGtstpRZEPcwkT+Rn+hL91f0u0Dayqvj9+JR6JqRnqWGm5MGXFaJla/+/jEWrtoE9uLaa4rk0kdp+7XmQwmvL7UVUMnJJhOP/TKImPH26jZhfeFRqjQk5Ju5ZsijVWX7Zk5JElx5ZkVt910/SrYqvn8wD8WwGXi+921O/vCnR79vb9oN7mL2PAWYLJChhuyC5Ja4kEG1krSablNyzM+GjXenlaJuTD/JNH2qrhy4ZlB4x92MtiiGGxKWrNoTub1lRdMqZoX7eqWlxx8a6LiE5Mwx+Hr2D1rfljiiKjuURD30rwdHXGsSv6dZJe7tcYc4tY1DFnav9mfurnlHlmbKJryRrzr1jyuuaMPMrKBJKjgZSYsh+19NeL+q9ObkDnp4FeE4GEK9YJKCwIJitguCG7kbs499d94Wrbgx0CMG1Q8yKPe7BDHTzQLqDID3u5L+FGunkk3BRWdJuf7CerRhsKbB/pVAfTVhzLmQemKGpemlHtVTfaR+tO4/KNm5jQp6Fas+mPWxMQ5t/fJruWymv+FWu0oITv1derZKTo536JCwM8aph+bM3m+nMoKQcnoONYoPdkwDtAv00mwrNWQGFBMJUzhhuyC4UtKVDZzbRfgeI+7KWQWCb1+/HfS2gd4I1f94epmXsLW+i6sOLcrg1qqNWvR339b7HnNKxDAFrW1ncpvXFfi5zt80a2V5PsVZiupfKYf8Var/v3qwW33bxu+rGyrlL1BkC1IKBqPSDDxCUJRv4ENB2UdxsDCtkRhhuq8GSell/2hKkJ91oFVMGw9gF5lkQoakmBORvOqJYPSz/wB7TwU0OppVbm5WWHi9y3uBYUU1eN/mh420Jfw+yuJWsUyZoqPQk4tlxfN6LLBrxkAkAT58k5sw64dhJo+aB+7hURf7lkr59wFbhxCdBlmR4yvPz09SrymrXbA60eAk6sAla/XPyx0sIjQUhGLcmtJCoX8n5mQCE7wXBDFZqMdpLh27HJ6Tnbtp6OVi0XTf0rI6hGpWJHLRmWFLCkpkTC1NsPtMKgeTuQkaXD4Nb+GN6xjlpN+6sd50vUglJaq0aXuGvJ1otkf3oEyCi+u86obbP1X3fNA5rdC1zYYXpxbfgeYON0/TEl9egyfajJLf/9wjz+O+DmBdy4ePsmhcIXzTgPIjvDcEMVVmpGFp7+br9a56lFrSroFFQNP+8JUxPUyU0+3B/vWrfIUUu5lxSwtMZEWoB+erqbaimR4dyG1qMx3YNK3IJi0ail8iyStfTY7GwgdDNMIsGmRmOgUT/A1VPfkhJxRN8iUxwJFPFXgOgQ/U2RVp+8o+WM+vu/t75x0HcPZWcC8fqareJZUIQt7x+fxvpbSUMkRx6RnWO4oQorJDJRBZvqlVzx+7M94OHqpELFl9vP4VpCGk5GJOC74EsmPZepo5uKY2yCO3OLc83qWiqPFhRLyHklRQNevvpgs/YVYP8i047t/w7Q/QXA0bHkK07fNxfwDgSCPwfSEoFq9QG/lsAPQ4s/VpYS6Pp/+lvVWwt9nt8OfH8/yh1HHhGZhOGGKuyIJ5lRWLSt462CjaEgV246nQ7f/HMBn2w8rdZ/Ko6po5tKpBTqV+Sn6u4h9Re3tkeGl03ri8xie+MCTLL0UX39S6vhQIM7gfRk4PCtmWyL88MwfQtMnS5AdgZw9RBMVv+OvMGmpCrVAPq9lTcYmdq11Khv3m1S5GvuyCNL531h3QxRsRhuqMKPePJwLfg2li6h8Xc0wJO96qPXB1ssWlLALLZev5KbFMeueQU4/JNp+8t8KUJmsJVbiV7rVs3M5b36rw6OQJ+pwLZZsNkJ4kp7aDRbX4jKHMMN2WQtjSwr0KepL1xurRpd1IgnWehSHjdWh2JxcW5Fql+R0T+mFr3+9TLgXgWo1wM4+isQew4mu3uGfv0gOS7mrH70kF9r4ND3xR977yf6IcohawC3KvrFFSXg7JxT/vOvWLMFha0vRGXKQSft93YkISEB3t7eiI+PR5UqVax9OmTEJxtO47MtoXipb2NM7N9EdUVJ60tRhcEydHrnlLsLDSlmrc5tSQvK5f3AN/m6MgqrI0mN03/Yy/Bd/9ZAVgaw58vij20xTF906ugEXDkAxJ6H2Sr5Ar1fAdZNLX7fZ7YDtdvl3WZq7YuxY621hII1X5eIyvTzmy03ZHNkKLdYcyxChRtT1mkqbsSTWcW5prag7P4M8GulDxmn/9bXkchIHlPIEGMDGcVzfitMdnJl3vvSAiKFsqa0wtw1HXD1AC7uBGp3ALpNAK6XoPWmtFmrJYMtKESaxHBDVi0KNoQMWcDxrT9P4LXBzXHiqn6dJFlMUpYSiEpILZURT2W2pMDer8w/VlZfrhIAtBkBpMUDMaHA9bNA6Kbij207CqjVVl8zI89TrzsQe8G0FpTG/fQtKN2fL51uGi6OSEQ2xCbCzYIFC/DRRx8hMjISbdu2xeeff44uXboY3ffrr7/G999/j+PH9TN2duzYEbNmzSp0f7ItxrqHfL3c4O7iiPAbNzFx2eE8SxZsPhUFNxf9SKhyHfEk3UQbcrWqFKXxQP1XGUEkNSSNBwDpKcCPw4o/duiXxrt4TAk3XScY7+IxF4tkiUgjrB5uli1bhkmTJmHhwoXo2rUr5s6di4EDB+L06dOoWVOmV89r27ZtGDVqFHr06AF3d3d88MEHGDBgAE6cOIGAgFsLxJFNKqwoODrp9r/2E2+tvO3p6qSWU9hwMgqd6lUr8nlLbcSTrNocuhE4vgI49qvpx931mvGAYg0skiUisn64+eSTTzB+/HiMGzdO3ZeQs2bNGixatAhTpxYsbvzpp7zDVb/55hv8/vvv2Lx5M8aMGVNu500l74oqbhmE3Mb3boB5m89i/8VYXMy1QnaZjHhyrwqE7Qa2f5h3rpfWj5Qs5NgCtqAQEVk33KSnp+PAgQOYNm1azjZHR0f069cPwcHBJj1HSkoKMjIyUL268X+1p6WlqVvuamsqf6YUBef2UIc6CI1OwpqjEbiWmKaCy4cPtcbHG86UbDkCU0Y85ebpA7R6UD9BnbRwmBturFm/whYUIrJzVg03MTExyMrKgp+fX57tcj8kxLD+S9GmTJmC2rVrq0BkzOzZszFz5sxSOV8yn6nLG/RsVAPN/KsgsLoHpt/bAttCriE5PQudg6rhoY6BGNq+TumPeBLu3kCvSUCX8YBrJcu7lli/QkRkv91Slnj//fexdOlSVYcj9TfGSKuQ1PTkbrkJDOSHQnkztdj3hbsa54xoklaZ6fe1wBurjuPxbvXKdsTTqGX60Ua5sX6FiKhCsmq48fHxgZOTE6KiovJsl/v+/v5FHvvxxx+rcLNp0ya0adOm0P3c3NzUjaxLWlhkgcvY5PQSFQWP7FIXD3cKLHYVbaNkgcSzG03b18WweFMubEEhIqqQrBpuXF1d1VBuKQYeOlS/Om92dra6/8ILLxR63Icffoj33nsP69evR6dOncrxjMlcEk7q+3gaDTfFFQWbHGwyUoEjP+uXIKjXEzj0IxBh4agltqAQEVU4Vu+Wki6jsWPHqpAic9XIUPDk5OSc0VMyAkqGeEvtjJCh3zNmzMDPP/+MoKAgNTeO8PLyUjeyTdGJaTh6WT85n4+XK2KS0k0vCi5sxJMsU7B5JpCWpF+v6OD3QMJl/WMnVhYyvoqIiLTO6uFmxIgRiI6OVoFFgkq7du2wbt26nCLjsLAwNYLK4Msvv1SjrIYPH57ned5880289dZb5X7+ZJrfDoQjI0uH9nWrYvmEHiUrCjZlxFPEIf1Xme23xQPAsd8AZ3dgwDvAb0+U/g9EREQ2y+rhRkgXVGHdUFIsnNvFixfL6ayoNOe4+XlPmPr+sa71Sl4UbOqIJ1nC4L65gKsnMOBdQJcNRJ2w4MyJiKgiut0kQlRGdpyNxuUbN1HF3Rn3tSmi68lS3Z7TBxshi1g6udwe8VQUrnlERKQpNtFyQ9r207/6VpvhHQPhbuI6UXlkpJj/4hzxRERkdxhuqExdjbuJLSH6of6Pdq1b8idIjAT+eNGyk+CIJyIiu8JwQ2bX0ZhSFLx0X7ha5bt7gxpoVLOEo9mys4DfxgGxoaV34kREpHkMN2TW6t6yCGbuNZ5q5RvOvfFkFGb8cVwNARePdatb/AKWhu6hU38BW97Vr/MkC1o6ewCZN8v+ByMiIk1guCGTnIlKxA/BlxDkUwnvri64undkfCqe/fEgvny8Awa29MecDadzwk/d6p4YEJABzO9c9KgnB0egwxjg8M9AVq7J/nr+B9j+QRn9ZEREpDUMN1SstMws/N8PB3AhJrnQKfEM26b8fgwuTo4IiUyEu4ujmtOmoa8XXGOOFT+cW4ZuH1ii/77xQKBqXaCyP9DmEWDXXPPXeCIiIrvCcEPF+mr7eRVsYMJcv/E3M/DUd/vV90Pa1EarAO+SvZh/O6B6EDBsYd71njjiiYiITMRwQ0UKu56C+Vv1Bb2Pd6uLH28N6zaFYSXvErl/HlC7XcHtHPFEREQmYripQCOPyptOp8Obfx5HWmY2ejaqgXtb1zIp3HSqVw1N/SujTZ3crTZc34mIiMoHw00FGHlkiV2hMViwNRSZWTp0a1gDY7vXw7zNZ1WR77ie9YsMVRtORmHr6Wi4ODng7QdaIahGJXVuUjxsLKo43FoEc9n/dS8Yzo4tt/hnISIiMgXDjRVbXyTYyAijokYeFRdwjL1uRPxNrDseqUYtvbzscM5w7L0XY7Fw+zmkZ2ar+19sO4fY5PRCQ5U8Lsb3bqCKgoU8LueWv7DY8JPK4wV+7tN/A8Hzi/w5iIiISouDTvoe7EhCQgK8vb0RHx+PKlWqlHvriwypDo9NQWV3F/xn6SEVZIyReFDDyxV7XuuHzOxsnI5MRJs6VYt9XWk5qebpglMRiXB1ckR6Vjbq+1TCkz2D8P7fIUhOz4JkD5lYz9hrCglVdap54r7Pd6pWm+BpfeHj5WZea9ONi8DCO4C0eNMu5jPbjdfcEBGRXUsowec3w42FCmt9yR0U5AM/O1uHuZvP4rPNZ0v0/ON6BiE89iY2nYrCpyPaYlj7OkW+rjE/PNUFvRv7IvRaEtafiMSSXRcRnWR8WLWcd80qbujd2AfLD1zBkLa18fmo9rd3uDURX5ZOhxNXEhCbko7qnq5oGVAFTg4O+lFL3nWA81uBo78CF3cC8eGAf1sgOgTIKmY4t4yKYuEwEVVgWVlZyMjIsPZpVEiurq5wdHS0+POb3VIWkC4hacEobN4XCQryeP8W/nh3zUks3nVRPdaiVhWERCYYbT3J7/vdF5F1a79FOy+qcFPU6xq4OjnggXYBaFjTSwUbIcsfRCdWw0frTxd6nDxnVEKaCjbi8dzrQUmwmd9RzTcjy1+2MfYEDk5Atfp5l0yQmYZH/qT/nsO5iUijpK0gMjIScXFx1j6VCkuCTf369VXIsQTDjQWk1iV314yxoCCP/7w3DEt264PNhw+1wSOdA/HtzvN4Z/WpYl/DEGzEsSvxeG/NSVU7U9TrivQsHR7sUAfdG+ad2E5qc0wlrTdSw5NDgkmxE/Fl6YONs7t+tuGgXkBQb8Dz1vMwvBCRRhmCTc2aNeHp6QkHac0mk2VnZ+Pq1auIiIhA3bp1Lbp+DDcWMDUoSFeUdP492CFABRvxRI/6WLj9fE6xrzE1KrkiITUDAVU90LxWFfx9PBJf/3PBovOTomNT/PhUF/S61eJTYv3eAtqPBir5mHc8EVEF7IoyBJsaNThburl8fX1VwMnMzISLi4vZz8NwYwFTg4IEmMruzpg2qHnONhlR9M4DLQutm5G8+t6wVmhdpyq8XJ0RGp2owo0UA0ttS4YJfVrGzk9aYkwZzt29oQXBpMFdDDZEZFcMNTbSYkPmM3RHSVhkuLGS4oKCkFDzdK/6uKtZTfhWvj3iSEihsRQcmzLyqGO96vjysQ6q2Hf/xRuY/XdIoedlCCh5upRyharZfavi45XB6r6x4dyT++abpyY9BQhZDez9qrhLQkRk19gVZRvXj+HGAhIAipv35aPhbYqcq0Yek4JjU+bIGdRa/zwyJPxg2A2sPxFVsvlmRFw47twwCHe6FVE7s8ENaHJr1NLl/cDSR4GkqGKuBhERkW0wPt6KTGZofZGWktzkvimT8AkJIVL4K6Ob5Gtxk//Jqtv/G+KHn+91wx2Vr6Clw4Wcm9z/6V433FMn0/jBphQFy+MyP83OucCSe/XBxrsu0HFcsT8LERGZT0bDBp+7jj8OX1Ff5X5FEhQUhLlz51r7NNhyUxpK0vpSKm4Nye6RmYYecj93b5d0+24GsL2QOWOys0x7je/uu/1944HA8EXA9VDgwOJS+RGIiKh8l+MpzJ133ol27dqVSijZt28fKlWqBGtjuCklhtaXErk1IV6J530xtfXl0A9A9Gng6kHAtTKQHA0kXzP9/HybAT1eBNqOAhyd9OcjE+0V9dryuOxHREQmK43leMpy/p6srCw4OzubNNrJFjDcWEuuCfGKDAqjV+oLerPSgZotgGpBpr/G9g/MP7+xq4H6vfNuk6AlrUGciI+IqNhAcDPDtJZy6Xp6888TRU4I+9afJ9GzkY9JPQIeLk4mF+Y+8cQT2L59u7rNmzdPbVu8eDHGjRuHtWvX4o033sCxY8ewYcMGBAYGYtKkSfj333+RnJyM5s2bY/bs2ejXr1+ebqmXX35Z3YScx9dff401a9Zg/fr1CAgIwJw5c3D//fejLDHcWKqsW18WD867zaM64NPEtHOr3QFocCfQ8C4gKwNw9wZuxgE/PVT8sW6VjW+Xn4XhhYioSBJsWsxYXyrPJQEnMiEVrd/aYNL+J98eCE9X0z7eJdCcOXMGrVq1wttvv622nThxQn2dOnUqPv74YzRo0ADVqlVDeHg4Bg8ejPfeew9ubm74/vvvMWTIEJw+fVpNuleYmTNn4sMPP8RHH32Ezz//HI899hguXbqE6tULjugtLQw35dH6Yul6SX6tJf4C104BN2OB8H9NO+6+TwsuQnn1sPnnQUREmuLt7a3mlpH5efz9/dW2kBD9VCMSdvr375+zr4SRtm3b5tx/5513sHLlSvz555944YUXimwdGjVqlPp+1qxZ+Oyzz7B3717cc889ZfZzMdxYwtTWl1N/6VtwZP/TawEHR8DVxImeHloEtH7o9nNFHQeO/gbs+dLy8yciojIhXUPSgmIKGYzyxOJ9xe63ZFxno/OXGXvt0tCpU6c895OSkvDWW2+pLiZZIkFmEb558ybCwsKKfJ42bW6vRCjFxrLo5bVrJaj/NAPDTXlYP838Y2s0zNsKFNBRvzilueGGRcFERGVOak1M7RqSxY1NmTle9iuzUbhG5B/1NHnyZGzcuFF1VTVq1AgeHh4YPnw40tPTUZT8Mw3LtZF1pMoSw015cK8G1G6rb7FpPABw9dKPYNq/qPzPhUXBREQVbkLYQidmLQWurq5qNFRxdu3apbqYhg0bltOSc/GiflFoW8NwUx4e+w0I7Jx3m39r88ONpa0vLAomIrIphS3H418O89wEBQVhz549Kqh4eXkV2qrSuHFjrFixQhURS+vL9OnTy7wFxlwMN+XByfzFv4xi6wsRkeaU+4Swubqbxo4dixYtWqgaGhkKbswnn3yCJ598Ej169ICPjw+mTJmChIQE2CKGG2th6wsREZXGhLAWatKkCYKD9YspG0j3k7EWni1btuTZ9vzzz+e5n7+bSub7yS8uLg5ljeHGWtj6QkREVCYYbizB1hciIiKbw3BjCba+EBER2RyGG0ux9YWIiMimOFr7BIiIiIhKE8MNERERaQrDDREREWkKww0RERFpCsMNERERaQpHSxEREVlbXDinFSlFDDdERETWDjbzOxY/IazMq1YGAefOO+9Eu3btMHfu3FJ5Plm6QZZYWLVqFayF3VJERETWJC02RQUbIY8X1bJDeTDcEBERlTZZMDI92bRb5k3TnlP2M+X5dAUXqyyqlWX79u2YN28eHBwc1E0Wvzx+/DgGDRoELy8v+Pn5YfTo0YiJick5bvny5WjdujU8PDxQo0YN9OvXD8nJyXjrrbfw3Xff4Y8//sh5vm3btqG8sVuKiIiotGWkALNql+5zLrrHtP1euwq4VjJpVwk1Z86cQatWrfD222+rbS4uLujSpQuefvppfPrpp7h58yamTJmCRx55RK0KHhERgVGjRuHDDz/EsGHDkJiYiH/++UetAD558mScOnUKCQkJWLx4sXq+6tWro7wx3BAREdkpb29vuLq6wtPTE/7+/mrbu+++i/bt22PWrFk5+y1atAiBgYEqCCUlJSEzMxMPPvgg6tWrpx6XVhwDac1JS0vLeT5rYLghIiIqbS6e+hYUU0QeNa1V5sl1gH8b017bAkeOHMHWrVtVl1R+586dw4ABA9C3b18VaAYOHKjuDx8+HNWqVYOtYLghIiIqbQ4OJncNwdnD9P1MfU4LSMvMkCFD8MEHHxR4rFatWnBycsLGjRuxe/dubNiwAZ9//jlef/117NmzB/Xr14ctYEExERGRHXN1dUVWVlbO/Q4dOuDEiRMICgpCo0aN8twqVdKHKykU7tmzJ2bOnIlDhw6p51i5cqXR57MGhhsiIiJrkgn6ZB6bosjjsl8ZCAoKUq0uMkpKRkQ9//zziI2NVUXD+/btU11R69evx7hx41RokX2lHmf//v0ICwvDihUrEB0djebNm+c839GjR3H69Gn1fBkZGShv7JYiIiKyJpmYTybos9IMxZMnT8bYsWPRokULNTLqwoUL2LVrlxohJfU0UhwshcP33HMPHB0dUaVKFezYsUNN+iejouSxOXPmqKHjYvz48Wr4d6dOnVQXl9TvyESB5clBJ2O37Ij8j5Dq8Pj4ePU/iIiIyFKpqakqFEjNibu7u7VPR5PXsSSf3+yWIiIiIk1huCEiIiJNYbghIiIiTWG4ISIiIk1huCEiIioldjZGx2avH8MNERGRhWSxSZGSkmLtU6nQ0tPT1VeZBdkSnOeGiIjIQvJhXLVqVVy7dk3dl4UoZRZfMl12draaDFCunbOzZfGE4YaIiKgUGFbBNgQcKjmZJLBu3boWB0OGGyIiolIgH8iysGTNmjWtsuSAFri6uqqAYymGGyIiolLuorK0ZoQ0UFC8YMECtdCWTLXctWtX7N27t8j9f/vtNzRr1kzt37p1a6xdu7bczpWIiIhsm9XDzbJlyzBp0iS8+eabOHjwINq2bYuBAwcW2me5e/dutVLpU089pZZZHzp0qLodP3683M+diIiIbI/VF86UlprOnTtj/vz5OdXSgYGBePHFFzF16tQC+48YMQLJyclYvXp1zrZu3bqhXbt2WLhwYbGvx4UziYiIKp6SfH47W3s8+4EDBzBt2rScbVJI1K9fPwQHBxs9RrZLS09u0tKzatUqo/vLUu1yM5CLYrhIREREVDEYPrdNaZOxariJiYlBVlYW/Pz88myX+yEhIUaPiYyMNLq/bDdm9uzZmDlzZoHt0jpEREREFUtiYqJqwbHr0VLSKpS7pUe6vWJjY1GjRo1Sn2BJUqWEpvDwcHZ5FYPXynS8VqbjtTIdr1XJ8HpZ/1pJi40Em9q1axe7r1XDjY+PjxouFxUVlWe73DdMhpSfbC/J/m5ubuqWm8wiWZbkfybf/KbhtTIdr5XpeK1Mx2tVMrxe1r1WxbXY2MRoKZmsp2PHjti8eXOelhW53717d6PHyPbc+4uNGzcWuj8RERHZF6t3S0mX0dixY9GpUyd06dIFc+fOVaOhxo0bpx4fM2YMAgICVO2MeOmll9CnTx/MmTMH9957L5YuXYr9+/fjq6++svJPQkRERLbA6uFGhnbLQlkzZsxQRcEypHvdunU5RcNhYWF5pmLu0aMHfv75Z7zxxht47bXX0LhxYzVSqlWrVrA26f6S+Xryd4NRQbxWpuO1Mh2vlel4rUqG16tiXSurz3NDREREpKkZiomIiIhKE8MNERERaQrDDREREWkKww0RERFpCsNNKVmwYAGCgoLg7u6uFgPdu3cv7N1bb72lZoHOfWvWrFnO46mpqXj++efVbNFeXl546KGHCkzQqGU7duzAkCFD1Gybcm3yr48mtf4yirBWrVrw8PBQa66dPXs2zz4y2/Zjjz2mJsqSySmfeuopJCUlwd6u1RNPPFHgvXbPPffY3bWSKTNkIeLKlSujZs2aGDp0KE6fPp1nH1N+72SUqky14enpqZ7n1VdfRWZmJuztWt15550F3lcTJkywu2slvvzyS7Rp0yZnYj6ZW+7vv/+Grb6vGG5KwbJly9R8PTL07eDBg2jbtq1azPPatWuwdy1btkRERETObefOnTmPTZw4EX/99Rd+++03bN++HVevXsWDDz4IeyHzOcl7RYKxMR9++CE+++wztdr9nj17UKlSJfW+kj8iBvJhfeLECTWR5erVq1UIeOaZZ2Bv10pImMn9Xvvll1/yPG4P10p+j+QD5t9//1U/Z0ZGBgYMGKCun6m/d7Len3wAycLGu3fvxnfffYclS5aooG1v10qMHz8+z/tKfi/t7VqJOnXq4P3331eLXcvccnfffTceeOAB9Ttlk+8rGQpOlunSpYvu+eefz7mflZWlq127tm727Nk6e/bmm2/q2rZta/SxuLg4nYuLi+63337L2Xbq1CmZlkAXHBysszfyc69cuTLnfnZ2ts7f31/30Ucf5blmbm5uul9++UXdP3nypDpu3759Ofv8/fffOgcHB92VK1d09nKtxNixY3UPPPBAocfY67W6du2a+rm3b99u8u/d2rVrdY6OjrrIyMicfb788ktdlSpVdGlpaTp7uVaiT58+updeeqnQY+z1WhlUq1ZN980339jk+4otNxaSFCpJVroMDGTSQbkfHBwMeyfdKNKV0KBBA/UvZ2mWFHLN5F9Kua+bdFnVrVuX1w3AhQsX1KSWua+PrKkiXZ6G6yNfpXtFZvc2kP3l/SctPfZm27Ztqqm7adOmePbZZ3H9+vWcx+z1WsXHx6uv1atXN/n3Tr62bt06ZyJVIS2Gshii4V/p9nCtDH766Se1DqJMFCsLMaekpOQ8Zq/XKisrS60OIK1c0j1li+8rq89QXNHFxMSo/9G5/4cJuR8SEgJ7Jh/E0uwoHzbSnDtz5kz07t0bx48fVx/csrZY/kVM5brJY/bOcA2Mva8Mj8lX+TDPzdnZWf1xtrdrKF1S0gRev359nDt3Ts1ePmjQIPUHVRbntcdrJev0vfzyy+jZs2fODO6m/N7JV2PvO8Nj9nKtxKOPPop69eqpf6AdPXoUU6ZMUXU5K1assMtrdezYMRVmpGtc6mpWrlyJFi1a4PDhwzb3vmK4oTIjHy4GUogmYUf+UPz666+qQJaotIwcOTLne/nXobzfGjZsqFpz+vbtC3sk9STyD4ncdW5UsmuVuyZL3ldS3C/vJwnQ8v6yN02bNlVBRlq5li9frtaFlPoaW8RuKQtJc6X8yzB/Vbjc9/f3t9p52SJJ9U2aNEFoaKi6NtKlFxcXl2cfXjc9wzUo6n0lX/MXrcvIAxkVZO/XULpB5XdT3mv2eK1eeOEFVTS9detWVQhqYMrvnXw19r4zPGYv18oY+QeayP2+sqdr5erqikaNGqFjx45qtJkU+c+bN88m31cMN6XwP1v+R2/evDlPE6fcl+Y7uk2G3cq/eORfP3LNXFxc8lw3ae6VmhxeN6juFfmFz319pG9a6kMM10e+yh8T6e822LJli3r/Gf4I26vLly+rmht5r9nTtZJ6a/mwlu4C+fnkfZSbKb938lW6H3KHQRlNJMN/pQvCXq6VMdJqIXK/r+zhWhVGfn/S0tJs831V6iXKdmjp0qVqFMuSJUvUqIxnnnlGV7Vq1TxV4fbolVde0W3btk134cIF3a5du3T9+vXT+fj4qFEJYsKECbq6devqtmzZotu/f7+ue/fu6mYvEhMTdYcOHVI3+VX85JNP1PeXLl1Sj7///vvqffTHH3/ojh49qkYD1a9fX3fz5s2c57jnnnt07du31+3Zs0e3c+dOXePGjXWjRo3S2dO1kscmT56sRmXIe23Tpk26Dh06qGuRmppqV9fq2Wef1Xl7e6vfu4iIiJxbSkpKzj7F/d5lZmbqWrVqpRswYIDu8OHDunXr1ul8fX1106ZN09nTtQoNDdW9/fbb6hrJ+0p+Dxs0aKC744477O5aialTp6qRZHIt5O+R3JfRhhs2bLDJ9xXDTSn5/PPP1f9YV1dXNTT833//1dm7ESNG6GrVqqWuSUBAgLovfzAM5EP6ueeeU8MJPT09dcOGDVN/XOzF1q1b1Qd1/psMazYMB58+fbrOz89Phee+ffvqTp8+nec5rl+/rj6gvby81JDKcePGqQ97e7pW8mEkfzDlD6UMR61Xr55u/PjxBf5xYQ/Xytg1ktvixYtL9Ht38eJF3aBBg3QeHh7qHyTyD5WMjAydPV2rsLAwFWSqV6+ufv8aNWqke/XVV3Xx8fF2d63Ek08+qX635O+5/K7J3yNDsLHF95WD/Kf024OIiIiIrIM1N0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdERESkKQw3REREpCkMN0RERKQpDDdEZHdkQU0HB4cCa+EQkTYw3BAREZGmMNwQERGRpjDcEJFVVhOePXu2WonZw8MDbdu2xfLly/N0Ga1ZswZt2rSBu7s7unXrhuPHj+d5jt9//x0tW7aEm5sbgoKCMGfOnDyPy2rFU6ZMQWBgoNqnUaNG+Pbbb/PsI6uEd+rUCZ6enujRo4daydjgyJEjuOuuu1C5cmW1crGsfLx///4yvS5EVDoYboio3Emw+f7777Fw4UKcOHECEydOxOOPP47t27fn7PPqq6+qwLJv3z74+vpiyJAhyMjIyAkljzzyCEaOHIljx47hrbfewvTp07FkyZKc48eMGYNffvkFn332GU6dOoX//e9/8PLyynMer7/+unoNCS3Ozs548skncx577LHHUKdOHfX68npTp06Fi4tLuVwfIrJQmSzHSURUiNTUVLVq8O7du/Nsf+qpp9Sq3YYVwJcuXZpnRW9ZSXjZsmXq/qOPPqrr379/nuNlxeYWLVqo72X1dHmOjRs3Gj0Hw2ts2rQpZ9uaNWvUNlndWFSuXFm3ZMmSUvzJiai8sOWGiMpVaGgoUlJS0L9/f9WSYrhJS865c+dy9uvevXvO99WrV0fTpk1VC4yQrz179szzvHL/7NmzyMrKwuHDh+Hk5IQ+ffoUeS7S7WVQq1Yt9fXatWvq66RJk/D000+jX79+eP/99/OcGxHZNoYbIipXSUlJ6qvU1EgIMdxOnjyZU3djKanjMUXubiap8zHUAwnp6pIus3vvvRdbtmxBixYtsHLlylI5PyIqWww3RFSuJCRIgW9YWJgq8s19k+Jfg3///Tfn+xs3buDMmTNo3ry5ui9fd+3aled55X6TJk1Ui03r1q1VSMldw2MOeT6pB9qwYQMefPBBLF682KLnI6Ly4VxOr0NEpMjoo8mTJ6vQIAGkV69eiI+PV+FERiXVq1dP7ff222+jRo0a8PPzU4W/Pj4+GDp0qHrslVdeQefOnfHOO+9gxIgRCA4Oxvz58/HFF1+ox2X01NixY1WBsBQUy2isS5cuqS4nKUQuzs2bN1VB8/Dhw9WIrsuXL6vC4oceeqiMrw4RlYpyq+4hIrolOztbN3fuXF3Tpk11Li4uOl9fX93AgQN127dvzyn2/euvv3QtW7bUubq66rp06aI7cuRInudYvny5KiCW4+vWrav76KOP8jwuhcETJ07U1apVSz1Ho0aNdIsWLVKPGV7jxo0bOfsfOnRIbbtw4YIuLS1NN3LkSF1gYKA6tnbt2roXXnghp9iYiGybg/yndGISEZHlZJ4bmV9GuqKqVq1q7dMhogqINTdERESkKQw3REREpCnsliIiIiJNYcsNERERaQrDDREREWkKww0RERFpCsMNERERaQrDDREREWkKww0RERFpCsMNERERaQrDDREREWkKww0RERFBS/4f17nqztki5yoAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os, sys\n",
        "print(os.getcwd())\n",
        "current_dir = os.path.dirname(os.getcwd())\n",
        "print(current_dir)\n",
        "os.chdir(current_dir)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
        "from common.trainer import Trainer\n",
        "\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "\n",
        "#오버피팅을 재현하기 위해 학습데이터 300으로 컷\n",
        "x_train = x_train[:300]\n",
        "t_train = t_train[:300]\n",
        "\n",
        "\n",
        "#drop out 사용 / 비율 설정 True -사용하겠다, False - 사용하지 않겠다\n",
        "use_dropout = True\n",
        "dropout_ratio = 0.3\n",
        "\n",
        "\n",
        "\n",
        "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
        "                        output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
        "\n",
        "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
        "                  epochs=301, mini_batch_size=100,\n",
        "                  optimizer='sgd', optimizer_param={'lr':0.01}, verbose=True)\n",
        "#Verbose??what for? 그리고 optimizer params 는 왜 배열로 지정해줌? {} ?\n",
        "\n",
        "#정의해준 trainer를 train 돌림. 학습! .train 이라는 메소드가 있나? Trainer에 있는 걸까?\n",
        "trainer.train()  \n",
        "\n",
        "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
        "\n",
        "\n",
        "# 그래프 그리기==========\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(len(train_acc_list))\n",
        "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
        "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](image-6.png)\n",
        "![alt text](image-7.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
